{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<img src=\".\\images\\Logo.png\" width=150 align=\"left\" /> <img src=\".\\images\\Logo2.jpg\" width=450 align=\"right\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "\n",
    "# <center><font color= #1e8449 > <b>CU53_impacto de las políticas de inversión en sanidad, infraestructuras y promoción turística en el SPI\t\t\t</font></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<font color='steelblue'><b>Citizenlab Data Science Methodology > III - Feature Engineering Domain </font>\n",
    "***\n",
    "> # <font color='steelblue'> <b>14.- Feature Data Transform</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<font color='steelblue'>Feature Data Transform is the process that allows change (if is required) the type and/or distribution of data features (e.g. scaling, normalizing o standardizing data features).</font>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## <font color='steelblue'>Tasks</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<font color='steelblue'><b>Perform Basic Data Transforms\t\t\t\t\t\t\n",
    "    \n",
    "<font color='steelblue'><b>Perform Categorical Variable Transformation\t\t\t\t\t\t\n",
    "- Encode Transformation\t\t\t\t\t\n",
    "    - One-hot encoding\t\t\t\t\n",
    "    - Ordinal encoding\t\t\t\t\n",
    "    - Dummy encoding\t\t\t\t\n",
    "- Evaluate a Logistic Regression model\t\t\t\t\t\n",
    "- Consider Embedding if text mining context\t\t\t\t\t\n",
    "    \n",
    "<font color='steelblue'><b>Perform Numeric Variable Transformation\t\t\t\t\t\t\n",
    "- Scale Transformation\t\t\t\t\t\n",
    "    - Normalization\t\t\t\t\n",
    "    - Standardization\t\t\t\t\n",
    "    - IQR Robust Scaler Transform\t\t\t\t\n",
    "    - Evaluate a KNN model\t\t\t\t\n",
    "- Distribution Transformation\t\t\t\t\t\n",
    "    - Discretization\t\t\t\t\n",
    "        - Uniform\t\t\t\n",
    "        - Clustered(k-Means)\t\t\t\n",
    "        - Quantile\t\t\t\n",
    "            - Normal Quantile\t\t\n",
    "            - Uniform Quantile\t\t\n",
    "            - Evaluate a KNN model\t\t\n",
    "        - Evaluate a KNN model\t\t\t\n",
    "    - Power transforms (Make Distributions More Gaussian)\t\t\t\t\n",
    "        - Box-Cox Transform\t\t\t\n",
    "        - Yeo-Johnson Transform\t\t\t\n",
    "        - Evaluate a KNN model\t\t\t\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Consideraciones casos CitizenLab programados en R\n",
    "\n",
    "* Algunas de las tareas de este proceso se han realizado en los notebooks del proceso 05 Data Collection porque eran necesarias para las tareas ETL. En esos casos, en este notebook se referencia al notebook del proceso 05 correspondiente\n",
    "* Otras tareas típicas de este proceso se realizan en los notebooks del dominio IV al ser más eficiente realizarlas en el propio pipeline de modelización.\n",
    "* Por tanto en los notebooks de este proceso de manera general se incluyen las comprobaciones necesarias, y comentarios si procede\n",
    "* Las tareas del proceso se van a aplicar solo a los archivos que forman parte del despliegue, ya que hay muchos archivos intermedios que no procede pasar por este proceso\n",
    "* El nombre de archivo del notebook hace referencia al nombre de archivo del proceso 05 al que se aplica este proceso, por eso pueden no ser correlativa la numeración\n",
    "* Las comprobaciones se van a realizar teniendo en cuenta que el lenguaje utilizado en el despliegue de este caso es R"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='green'>File</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- <font color='steelblue'> <b>Input File: CU_53_09.2_02_spi</font>\n",
    "- <font color='steelblue'> <b>Output File: CU_53_14_02_spi</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoding\n",
    "\n",
    "Con la siguiente expresión se evitan problemas con el encoding al ejecutar el notebook. Es posible que deba ser eliminada o adaptada a la máquina en la que se ejecute el código."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "'LC_CTYPE=es_ES.UTF-8;LC_NUMERIC=C;LC_TIME=es_ES.UTF-8;LC_COLLATE=es_ES.UTF-8;LC_MONETARY=es_ES.UTF-8;LC_MESSAGES=en_US.UTF-8;LC_PAPER=es_ES.UTF-8;LC_NAME=C;LC_ADDRESS=C;LC_TELEPHONE=C;LC_MEASUREMENT=es_ES.UTF-8;LC_IDENTIFICATION=C'"
      ],
      "text/latex": [
       "'LC\\_CTYPE=es\\_ES.UTF-8;LC\\_NUMERIC=C;LC\\_TIME=es\\_ES.UTF-8;LC\\_COLLATE=es\\_ES.UTF-8;LC\\_MONETARY=es\\_ES.UTF-8;LC\\_MESSAGES=en\\_US.UTF-8;LC\\_PAPER=es\\_ES.UTF-8;LC\\_NAME=C;LC\\_ADDRESS=C;LC\\_TELEPHONE=C;LC\\_MEASUREMENT=es\\_ES.UTF-8;LC\\_IDENTIFICATION=C'"
      ],
      "text/markdown": [
       "'LC_CTYPE=es_ES.UTF-8;LC_NUMERIC=C;LC_TIME=es_ES.UTF-8;LC_COLLATE=es_ES.UTF-8;LC_MONETARY=es_ES.UTF-8;LC_MESSAGES=en_US.UTF-8;LC_PAPER=es_ES.UTF-8;LC_NAME=C;LC_ADDRESS=C;LC_TELEPHONE=C;LC_MEASUREMENT=es_ES.UTF-8;LC_IDENTIFICATION=C'"
      ],
      "text/plain": [
       "[1] \"LC_CTYPE=es_ES.UTF-8;LC_NUMERIC=C;LC_TIME=es_ES.UTF-8;LC_COLLATE=es_ES.UTF-8;LC_MONETARY=es_ES.UTF-8;LC_MESSAGES=en_US.UTF-8;LC_PAPER=es_ES.UTF-8;LC_NAME=C;LC_ADDRESS=C;LC_TELEPHONE=C;LC_MEASUREMENT=es_ES.UTF-8;LC_IDENTIFICATION=C\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "Sys.setlocale(category = \"LC_ALL\", locale = \"es_ES.UTF-8\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='green'>Settings</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Libraries to use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Attaching package: ‘dplyr’\n",
      "\n",
      "\n",
      "The following objects are masked from ‘package:stats’:\n",
      "\n",
      "    filter, lag\n",
      "\n",
      "\n",
      "The following objects are masked from ‘package:base’:\n",
      "\n",
      "    intersect, setdiff, setequal, union\n",
      "\n",
      "\n",
      "\n",
      "Attaching package: ‘lubridate’\n",
      "\n",
      "\n",
      "The following objects are masked from ‘package:base’:\n",
      "\n",
      "    date, intersect, setdiff, union\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "library(readr)\n",
    "library(dplyr)\n",
    "library(tidyr)\n",
    "library(forcats)\n",
    "library(lubridate)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "iPath <- \"Data/Input/\"\n",
    "oPath <- \"Data/Output/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='green'>Data Load</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='tomato'><b> OPCION A:</b> Seleccionar fichero en ventana para mayor comodidad</font> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data load using the {tcltk} package. Ucomment the line if using this option"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# file_data <- tcltk::tk_choose.files(multi = FALSE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='tomato'><b> OPCION B:</b> Especificar el nombre de archivo</font>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Se leerán datos del archivo:  Data/Input/CU_53_09.2_02_spi.csv"
     ]
    }
   ],
   "source": [
    "iFile <- \"CU_53_09.2_02_spi.csv\"\n",
    "file_data <- paste0(iPath, iFile)\n",
    "\n",
    "if(file.exists(file_data)){\n",
    "    cat(\"Se leerán datos del archivo: \", file_data)\n",
    "} else{\n",
    "    warning(\"Cuidado: el archivo no existe.\")\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data file to dataframe\n",
    "\n",
    "Usar la función adecuada según el formato de entrada (xlsx, csv, json, ...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1mRows: \u001b[22m\u001b[34m2028\u001b[39m \u001b[1mColumns: \u001b[22m\u001b[34m18\u001b[39m\n",
      "\u001b[36m──\u001b[39m \u001b[1mColumn specification\u001b[22m \u001b[36m────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\u001b[39m\n",
      "\u001b[1mDelimiter:\u001b[22m \",\"\n",
      "\u001b[32mdbl\u001b[39m (17): rank_score_spi, score_spi, score_bhn, score_fow, score_opp, score_...\n",
      "\u001b[33mlgl\u001b[39m  (1): is_train\n",
      "\n",
      "\u001b[36mℹ\u001b[39m Use `spec()` to retrieve the full column specification for this data.\n",
      "\u001b[36mℹ\u001b[39m Specify the column types or set `show_col_types = FALSE` to quiet this message.\n"
     ]
    }
   ],
   "source": [
    "data <- read_csv(file_data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Estructura de  los datos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows: 2,028\n",
      "Columns: 18\n",
      "$ rank_score_spi \u001b[3m\u001b[90m<dbl>\u001b[39m\u001b[23m 80, 97, 46, 84, 99, 150, 74, 105, 36, 143, 154, 69, 168…\n",
      "$ score_spi      \u001b[3m\u001b[90m<dbl>\u001b[39m\u001b[23m 67.59, 60.10, 73.96, 62.86, 61.43, 45.57, 66.56, 59.45,…\n",
      "$ score_bhn      \u001b[3m\u001b[90m<dbl>\u001b[39m\u001b[23m 79.16, 74.55, 81.88, 79.45, 77.84, 47.15, 80.41, 66.16,…\n",
      "$ score_fow      \u001b[3m\u001b[90m<dbl>\u001b[39m\u001b[23m 65.40, 51.25, 70.69, 61.22, 57.63, 45.21, 62.82, 54.62,…\n",
      "$ score_opp      \u001b[3m\u001b[90m<dbl>\u001b[39m\u001b[23m 58.22, 54.49, 69.32, 47.92, 48.83, 44.34, 56.46, 57.56,…\n",
      "$ score_nbmc     \u001b[3m\u001b[90m<dbl>\u001b[39m\u001b[23m 86.67, 72.88, 86.33, 83.91, 87.72, 54.66, 92.38, 72.21,…\n",
      "$ score_ws       \u001b[3m\u001b[90m<dbl>\u001b[39m\u001b[23m 86.44, 83.35, 88.07, 77.71, 78.15, 47.82, 78.47, 66.32,…\n",
      "$ score_sh       \u001b[3m\u001b[90m<dbl>\u001b[39m\u001b[23m 87.69, 77.17, 89.59, 85.11, 86.61, 36.59, 85.21, 75.91,…\n",
      "$ score_ps       \u001b[3m\u001b[90m<dbl>\u001b[39m\u001b[23m 55.85, 64.81, 63.55, 71.08, 58.87, 49.53, 65.57, 50.21,…\n",
      "$ score_abk      \u001b[3m\u001b[90m<dbl>\u001b[39m\u001b[23m 74.20, 47.04, 89.07, 65.15, 55.79, 50.36, 81.61, 68.71,…\n",
      "$ score_aic      \u001b[3m\u001b[90m<dbl>\u001b[39m\u001b[23m 74.19, 37.15, 68.14, 51.25, 78.17, 33.84, 61.95, 56.61,…\n",
      "$ score_hw       \u001b[3m\u001b[90m<dbl>\u001b[39m\u001b[23m 53.55, 64.58, 61.41, 62.00, 45.35, 36.99, 61.64, 41.87,…\n",
      "$ score_eq       \u001b[3m\u001b[90m<dbl>\u001b[39m\u001b[23m 59.66, 56.22, 64.13, 66.47, 51.22, 59.66, 46.07, 51.28,…\n",
      "$ score_pr       \u001b[3m\u001b[90m<dbl>\u001b[39m\u001b[23m 81.60, 71.05, 90.28, 61.56, 60.41, 69.20, 70.02, 74.13,…\n",
      "$ score_pfc      \u001b[3m\u001b[90m<dbl>\u001b[39m\u001b[23m 60.29, 64.77, 67.65, 56.51, 58.62, 40.61, 62.49, 59.83,…\n",
      "$ score_incl     \u001b[3m\u001b[90m<dbl>\u001b[39m\u001b[23m 40.24, 56.12, 68.48, 48.70, 35.57, 41.81, 36.89, 55.73,…\n",
      "$ score_aae      \u001b[3m\u001b[90m<dbl>\u001b[39m\u001b[23m 50.73, 26.03, 50.87, 24.90, 40.72, 25.72, 56.45, 40.54,…\n",
      "$ is_train       \u001b[3m\u001b[90m<lgl>\u001b[39m\u001b[23m TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, T…\n"
     ]
    }
   ],
   "source": [
    "data |> glimpse()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Muestra de los primeros datos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"dataframe\">\n",
       "<caption>A spec_tbl_df: 5 × 18</caption>\n",
       "<thead>\n",
       "\t<tr><th scope=col>rank_score_spi</th><th scope=col>score_spi</th><th scope=col>score_bhn</th><th scope=col>score_fow</th><th scope=col>score_opp</th><th scope=col>score_nbmc</th><th scope=col>score_ws</th><th scope=col>score_sh</th><th scope=col>score_ps</th><th scope=col>score_abk</th><th scope=col>score_aic</th><th scope=col>score_hw</th><th scope=col>score_eq</th><th scope=col>score_pr</th><th scope=col>score_pfc</th><th scope=col>score_incl</th><th scope=col>score_aae</th><th scope=col>is_train</th></tr>\n",
       "\t<tr><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;lgl&gt;</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "\t<tr><td>80</td><td>67.59</td><td>79.16</td><td>65.40</td><td>58.22</td><td>86.67</td><td>86.44</td><td>87.69</td><td>55.85</td><td>74.20</td><td>74.19</td><td>53.55</td><td>59.66</td><td>81.60</td><td>60.29</td><td>40.24</td><td>50.73</td><td>TRUE</td></tr>\n",
       "\t<tr><td>97</td><td>60.10</td><td>74.55</td><td>51.25</td><td>54.49</td><td>72.88</td><td>83.35</td><td>77.17</td><td>64.81</td><td>47.04</td><td>37.15</td><td>64.58</td><td>56.22</td><td>71.05</td><td>64.77</td><td>56.12</td><td>26.03</td><td>TRUE</td></tr>\n",
       "\t<tr><td>46</td><td>73.96</td><td>81.88</td><td>70.69</td><td>69.32</td><td>86.33</td><td>88.07</td><td>89.59</td><td>63.55</td><td>89.07</td><td>68.14</td><td>61.41</td><td>64.13</td><td>90.28</td><td>67.65</td><td>68.48</td><td>50.87</td><td>TRUE</td></tr>\n",
       "\t<tr><td>84</td><td>62.86</td><td>79.45</td><td>61.22</td><td>47.92</td><td>83.91</td><td>77.71</td><td>85.11</td><td>71.08</td><td>65.15</td><td>51.25</td><td>62.00</td><td>66.47</td><td>61.56</td><td>56.51</td><td>48.70</td><td>24.90</td><td>TRUE</td></tr>\n",
       "\t<tr><td>99</td><td>61.43</td><td>77.84</td><td>57.63</td><td>48.83</td><td>87.72</td><td>78.15</td><td>86.61</td><td>58.87</td><td>55.79</td><td>78.17</td><td>45.35</td><td>51.22</td><td>60.41</td><td>58.62</td><td>35.57</td><td>40.72</td><td>TRUE</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A spec\\_tbl\\_df: 5 × 18\n",
       "\\begin{tabular}{llllllllllllllllll}\n",
       " rank\\_score\\_spi & score\\_spi & score\\_bhn & score\\_fow & score\\_opp & score\\_nbmc & score\\_ws & score\\_sh & score\\_ps & score\\_abk & score\\_aic & score\\_hw & score\\_eq & score\\_pr & score\\_pfc & score\\_incl & score\\_aae & is\\_train\\\\\n",
       " <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <lgl>\\\\\n",
       "\\hline\n",
       "\t 80 & 67.59 & 79.16 & 65.40 & 58.22 & 86.67 & 86.44 & 87.69 & 55.85 & 74.20 & 74.19 & 53.55 & 59.66 & 81.60 & 60.29 & 40.24 & 50.73 & TRUE\\\\\n",
       "\t 97 & 60.10 & 74.55 & 51.25 & 54.49 & 72.88 & 83.35 & 77.17 & 64.81 & 47.04 & 37.15 & 64.58 & 56.22 & 71.05 & 64.77 & 56.12 & 26.03 & TRUE\\\\\n",
       "\t 46 & 73.96 & 81.88 & 70.69 & 69.32 & 86.33 & 88.07 & 89.59 & 63.55 & 89.07 & 68.14 & 61.41 & 64.13 & 90.28 & 67.65 & 68.48 & 50.87 & TRUE\\\\\n",
       "\t 84 & 62.86 & 79.45 & 61.22 & 47.92 & 83.91 & 77.71 & 85.11 & 71.08 & 65.15 & 51.25 & 62.00 & 66.47 & 61.56 & 56.51 & 48.70 & 24.90 & TRUE\\\\\n",
       "\t 99 & 61.43 & 77.84 & 57.63 & 48.83 & 87.72 & 78.15 & 86.61 & 58.87 & 55.79 & 78.17 & 45.35 & 51.22 & 60.41 & 58.62 & 35.57 & 40.72 & TRUE\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A spec_tbl_df: 5 × 18\n",
       "\n",
       "| rank_score_spi &lt;dbl&gt; | score_spi &lt;dbl&gt; | score_bhn &lt;dbl&gt; | score_fow &lt;dbl&gt; | score_opp &lt;dbl&gt; | score_nbmc &lt;dbl&gt; | score_ws &lt;dbl&gt; | score_sh &lt;dbl&gt; | score_ps &lt;dbl&gt; | score_abk &lt;dbl&gt; | score_aic &lt;dbl&gt; | score_hw &lt;dbl&gt; | score_eq &lt;dbl&gt; | score_pr &lt;dbl&gt; | score_pfc &lt;dbl&gt; | score_incl &lt;dbl&gt; | score_aae &lt;dbl&gt; | is_train &lt;lgl&gt; |\n",
       "|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|\n",
       "| 80 | 67.59 | 79.16 | 65.40 | 58.22 | 86.67 | 86.44 | 87.69 | 55.85 | 74.20 | 74.19 | 53.55 | 59.66 | 81.60 | 60.29 | 40.24 | 50.73 | TRUE |\n",
       "| 97 | 60.10 | 74.55 | 51.25 | 54.49 | 72.88 | 83.35 | 77.17 | 64.81 | 47.04 | 37.15 | 64.58 | 56.22 | 71.05 | 64.77 | 56.12 | 26.03 | TRUE |\n",
       "| 46 | 73.96 | 81.88 | 70.69 | 69.32 | 86.33 | 88.07 | 89.59 | 63.55 | 89.07 | 68.14 | 61.41 | 64.13 | 90.28 | 67.65 | 68.48 | 50.87 | TRUE |\n",
       "| 84 | 62.86 | 79.45 | 61.22 | 47.92 | 83.91 | 77.71 | 85.11 | 71.08 | 65.15 | 51.25 | 62.00 | 66.47 | 61.56 | 56.51 | 48.70 | 24.90 | TRUE |\n",
       "| 99 | 61.43 | 77.84 | 57.63 | 48.83 | 87.72 | 78.15 | 86.61 | 58.87 | 55.79 | 78.17 | 45.35 | 51.22 | 60.41 | 58.62 | 35.57 | 40.72 | TRUE |\n",
       "\n"
      ],
      "text/plain": [
       "  rank_score_spi score_spi score_bhn score_fow score_opp score_nbmc score_ws\n",
       "1 80             67.59     79.16     65.40     58.22     86.67      86.44   \n",
       "2 97             60.10     74.55     51.25     54.49     72.88      83.35   \n",
       "3 46             73.96     81.88     70.69     69.32     86.33      88.07   \n",
       "4 84             62.86     79.45     61.22     47.92     83.91      77.71   \n",
       "5 99             61.43     77.84     57.63     48.83     87.72      78.15   \n",
       "  score_sh score_ps score_abk score_aic score_hw score_eq score_pr score_pfc\n",
       "1 87.69    55.85    74.20     74.19     53.55    59.66    81.60    60.29    \n",
       "2 77.17    64.81    47.04     37.15     64.58    56.22    71.05    64.77    \n",
       "3 89.59    63.55    89.07     68.14     61.41    64.13    90.28    67.65    \n",
       "4 85.11    71.08    65.15     51.25     62.00    66.47    61.56    56.51    \n",
       "5 86.61    58.87    55.79     78.17     45.35    51.22    60.41    58.62    \n",
       "  score_incl score_aae is_train\n",
       "1 40.24      50.73     TRUE    \n",
       "2 56.12      26.03     TRUE    \n",
       "3 68.48      50.87     TRUE    \n",
       "4 48.70      24.90     TRUE    \n",
       "5 35.57      40.72     TRUE    "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data |> slice_head(n = 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Basic Data Transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Data Selecting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-30T14:33:43.649449Z",
     "start_time": "2020-06-30T14:33:43.611681Z"
    },
    "scrolled": true,
    "slideshow": {
     "slide_type": "subslide"
    },
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"dataframe\">\n",
       "<caption>A tibble: 2028 × 1</caption>\n",
       "<thead>\n",
       "\t<tr><th scope=col>rank_score_spi</th></tr>\n",
       "\t<tr><th scope=col>&lt;dbl&gt;</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "\t<tr><td> 80</td></tr>\n",
       "\t<tr><td> 97</td></tr>\n",
       "\t<tr><td> 46</td></tr>\n",
       "\t<tr><td> 84</td></tr>\n",
       "\t<tr><td> 99</td></tr>\n",
       "\t<tr><td>150</td></tr>\n",
       "\t<tr><td> 74</td></tr>\n",
       "\t<tr><td>105</td></tr>\n",
       "\t<tr><td> 36</td></tr>\n",
       "\t<tr><td>143</td></tr>\n",
       "\t<tr><td>154</td></tr>\n",
       "\t<tr><td> 69</td></tr>\n",
       "\t<tr><td>168</td></tr>\n",
       "\t<tr><td>141</td></tr>\n",
       "\t<tr><td>164</td></tr>\n",
       "\t<tr><td>  1</td></tr>\n",
       "\t<tr><td> 64</td></tr>\n",
       "\t<tr><td> 75</td></tr>\n",
       "\t<tr><td>125</td></tr>\n",
       "\t<tr><td> 86</td></tr>\n",
       "\t<tr><td> 27</td></tr>\n",
       "\t<tr><td> 81</td></tr>\n",
       "\t<tr><td>144</td></tr>\n",
       "\t<tr><td>102</td></tr>\n",
       "\t<tr><td> 30</td></tr>\n",
       "\t<tr><td>126</td></tr>\n",
       "\t<tr><td> 25</td></tr>\n",
       "\t<tr><td> 78</td></tr>\n",
       "\t<tr><td>129</td></tr>\n",
       "\t<tr><td>123</td></tr>\n",
       "\t<tr><td>⋮</td></tr>\n",
       "\t<tr><td> 56</td></tr>\n",
       "\t<tr><td> 81</td></tr>\n",
       "\t<tr><td> 12</td></tr>\n",
       "\t<tr><td> 16</td></tr>\n",
       "\t<tr><td> 19</td></tr>\n",
       "\t<tr><td> 19</td></tr>\n",
       "\t<tr><td> 20</td></tr>\n",
       "\t<tr><td> 23</td></tr>\n",
       "\t<tr><td> 24</td></tr>\n",
       "\t<tr><td> 38</td></tr>\n",
       "\t<tr><td> 39</td></tr>\n",
       "\t<tr><td>108</td></tr>\n",
       "\t<tr><td>103</td></tr>\n",
       "\t<tr><td> 99</td></tr>\n",
       "\t<tr><td> 90</td></tr>\n",
       "\t<tr><td> 86</td></tr>\n",
       "\t<tr><td> 84</td></tr>\n",
       "\t<tr><td> 92</td></tr>\n",
       "\t<tr><td> 92</td></tr>\n",
       "\t<tr><td> 91</td></tr>\n",
       "\t<tr><td>159</td></tr>\n",
       "\t<tr><td>133</td></tr>\n",
       "\t<tr><td>130</td></tr>\n",
       "\t<tr><td>131</td></tr>\n",
       "\t<tr><td>133</td></tr>\n",
       "\t<tr><td>131</td></tr>\n",
       "\t<tr><td>137</td></tr>\n",
       "\t<tr><td>125</td></tr>\n",
       "\t<tr><td>130</td></tr>\n",
       "\t<tr><td>131</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A tibble: 2028 × 1\n",
       "\\begin{tabular}{l}\n",
       " rank\\_score\\_spi\\\\\n",
       " <dbl>\\\\\n",
       "\\hline\n",
       "\t  80\\\\\n",
       "\t  97\\\\\n",
       "\t  46\\\\\n",
       "\t  84\\\\\n",
       "\t  99\\\\\n",
       "\t 150\\\\\n",
       "\t  74\\\\\n",
       "\t 105\\\\\n",
       "\t  36\\\\\n",
       "\t 143\\\\\n",
       "\t 154\\\\\n",
       "\t  69\\\\\n",
       "\t 168\\\\\n",
       "\t 141\\\\\n",
       "\t 164\\\\\n",
       "\t   1\\\\\n",
       "\t  64\\\\\n",
       "\t  75\\\\\n",
       "\t 125\\\\\n",
       "\t  86\\\\\n",
       "\t  27\\\\\n",
       "\t  81\\\\\n",
       "\t 144\\\\\n",
       "\t 102\\\\\n",
       "\t  30\\\\\n",
       "\t 126\\\\\n",
       "\t  25\\\\\n",
       "\t  78\\\\\n",
       "\t 129\\\\\n",
       "\t 123\\\\\n",
       "\t ⋮\\\\\n",
       "\t  56\\\\\n",
       "\t  81\\\\\n",
       "\t  12\\\\\n",
       "\t  16\\\\\n",
       "\t  19\\\\\n",
       "\t  19\\\\\n",
       "\t  20\\\\\n",
       "\t  23\\\\\n",
       "\t  24\\\\\n",
       "\t  38\\\\\n",
       "\t  39\\\\\n",
       "\t 108\\\\\n",
       "\t 103\\\\\n",
       "\t  99\\\\\n",
       "\t  90\\\\\n",
       "\t  86\\\\\n",
       "\t  84\\\\\n",
       "\t  92\\\\\n",
       "\t  92\\\\\n",
       "\t  91\\\\\n",
       "\t 159\\\\\n",
       "\t 133\\\\\n",
       "\t 130\\\\\n",
       "\t 131\\\\\n",
       "\t 133\\\\\n",
       "\t 131\\\\\n",
       "\t 137\\\\\n",
       "\t 125\\\\\n",
       "\t 130\\\\\n",
       "\t 131\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A tibble: 2028 × 1\n",
       "\n",
       "| rank_score_spi &lt;dbl&gt; |\n",
       "|---|\n",
       "|  80 |\n",
       "|  97 |\n",
       "|  46 |\n",
       "|  84 |\n",
       "|  99 |\n",
       "| 150 |\n",
       "|  74 |\n",
       "| 105 |\n",
       "|  36 |\n",
       "| 143 |\n",
       "| 154 |\n",
       "|  69 |\n",
       "| 168 |\n",
       "| 141 |\n",
       "| 164 |\n",
       "|   1 |\n",
       "|  64 |\n",
       "|  75 |\n",
       "| 125 |\n",
       "|  86 |\n",
       "|  27 |\n",
       "|  81 |\n",
       "| 144 |\n",
       "| 102 |\n",
       "|  30 |\n",
       "| 126 |\n",
       "|  25 |\n",
       "|  78 |\n",
       "| 129 |\n",
       "| 123 |\n",
       "| ⋮ |\n",
       "|  56 |\n",
       "|  81 |\n",
       "|  12 |\n",
       "|  16 |\n",
       "|  19 |\n",
       "|  19 |\n",
       "|  20 |\n",
       "|  23 |\n",
       "|  24 |\n",
       "|  38 |\n",
       "|  39 |\n",
       "| 108 |\n",
       "| 103 |\n",
       "|  99 |\n",
       "|  90 |\n",
       "|  86 |\n",
       "|  84 |\n",
       "|  92 |\n",
       "|  92 |\n",
       "|  91 |\n",
       "| 159 |\n",
       "| 133 |\n",
       "| 130 |\n",
       "| 131 |\n",
       "| 133 |\n",
       "| 131 |\n",
       "| 137 |\n",
       "| 125 |\n",
       "| 130 |\n",
       "| 131 |\n",
       "\n"
      ],
      "text/plain": [
       "     rank_score_spi\n",
       "1     80           \n",
       "2     97           \n",
       "3     46           \n",
       "4     84           \n",
       "5     99           \n",
       "6    150           \n",
       "7     74           \n",
       "8    105           \n",
       "9     36           \n",
       "10   143           \n",
       "11   154           \n",
       "12    69           \n",
       "13   168           \n",
       "14   141           \n",
       "15   164           \n",
       "16     1           \n",
       "17    64           \n",
       "18    75           \n",
       "19   125           \n",
       "20    86           \n",
       "21    27           \n",
       "22    81           \n",
       "23   144           \n",
       "24   102           \n",
       "25    30           \n",
       "26   126           \n",
       "27    25           \n",
       "28    78           \n",
       "29   129           \n",
       "30   123           \n",
       "⋮    ⋮             \n",
       "1999  56           \n",
       "2000  81           \n",
       "2001  12           \n",
       "2002  16           \n",
       "2003  19           \n",
       "2004  19           \n",
       "2005  20           \n",
       "2006  23           \n",
       "2007  24           \n",
       "2008  38           \n",
       "2009  39           \n",
       "2010 108           \n",
       "2011 103           \n",
       "2012  99           \n",
       "2013  90           \n",
       "2014  86           \n",
       "2015  84           \n",
       "2016  92           \n",
       "2017  92           \n",
       "2018  91           \n",
       "2019 159           \n",
       "2020 133           \n",
       "2021 130           \n",
       "2022 131           \n",
       "2023 133           \n",
       "2024 131           \n",
       "2025 137           \n",
       "2026 125           \n",
       "2027 130           \n",
       "2028 131           "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data |> select(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Data Filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-30T14:33:43.649449Z",
     "start_time": "2020-06-30T14:33:43.611681Z"
    },
    "scrolled": true,
    "slideshow": {
     "slide_type": "subslide"
    },
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# data |> filter(ano = 2019)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Insert New Column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-30T14:33:43.649449Z",
     "start_time": "2020-06-30T14:33:43.611681Z"
    },
    "scrolled": true,
    "slideshow": {
     "slide_type": "subslide"
    },
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"dataframe\">\n",
       "<caption>A tibble: 2028 × 19</caption>\n",
       "<thead>\n",
       "\t<tr><th scope=col>rank_score_spi</th><th scope=col>score_spi</th><th scope=col>score_bhn</th><th scope=col>score_fow</th><th scope=col>score_opp</th><th scope=col>score_nbmc</th><th scope=col>score_ws</th><th scope=col>score_sh</th><th scope=col>score_ps</th><th scope=col>score_abk</th><th scope=col>score_aic</th><th scope=col>score_hw</th><th scope=col>score_eq</th><th scope=col>score_pr</th><th scope=col>score_pfc</th><th scope=col>score_incl</th><th scope=col>score_aae</th><th scope=col>is_train</th><th scope=col>x</th></tr>\n",
       "\t<tr><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;lgl&gt;</th><th scope=col>&lt;lgl&gt;</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "\t<tr><td> 80</td><td>67.59</td><td>79.16</td><td>65.40</td><td>58.22</td><td>86.67</td><td>86.44</td><td>87.69</td><td>55.85</td><td>74.20</td><td>74.19</td><td>53.55</td><td>59.66</td><td>81.60</td><td>60.29</td><td>40.24</td><td>50.73</td><td>TRUE</td><td>TRUE</td></tr>\n",
       "\t<tr><td> 97</td><td>60.10</td><td>74.55</td><td>51.25</td><td>54.49</td><td>72.88</td><td>83.35</td><td>77.17</td><td>64.81</td><td>47.04</td><td>37.15</td><td>64.58</td><td>56.22</td><td>71.05</td><td>64.77</td><td>56.12</td><td>26.03</td><td>TRUE</td><td>TRUE</td></tr>\n",
       "\t<tr><td> 46</td><td>73.96</td><td>81.88</td><td>70.69</td><td>69.32</td><td>86.33</td><td>88.07</td><td>89.59</td><td>63.55</td><td>89.07</td><td>68.14</td><td>61.41</td><td>64.13</td><td>90.28</td><td>67.65</td><td>68.48</td><td>50.87</td><td>TRUE</td><td>TRUE</td></tr>\n",
       "\t<tr><td> 84</td><td>62.86</td><td>79.45</td><td>61.22</td><td>47.92</td><td>83.91</td><td>77.71</td><td>85.11</td><td>71.08</td><td>65.15</td><td>51.25</td><td>62.00</td><td>66.47</td><td>61.56</td><td>56.51</td><td>48.70</td><td>24.90</td><td>TRUE</td><td>TRUE</td></tr>\n",
       "\t<tr><td> 99</td><td>61.43</td><td>77.84</td><td>57.63</td><td>48.83</td><td>87.72</td><td>78.15</td><td>86.61</td><td>58.87</td><td>55.79</td><td>78.17</td><td>45.35</td><td>51.22</td><td>60.41</td><td>58.62</td><td>35.57</td><td>40.72</td><td>TRUE</td><td>TRUE</td></tr>\n",
       "\t<tr><td>150</td><td>45.57</td><td>47.15</td><td>45.21</td><td>44.34</td><td>54.66</td><td>47.82</td><td>36.59</td><td>49.53</td><td>50.36</td><td>33.84</td><td>36.99</td><td>59.66</td><td>69.20</td><td>40.61</td><td>41.81</td><td>25.72</td><td>TRUE</td><td>TRUE</td></tr>\n",
       "\t<tr><td> 74</td><td>66.56</td><td>80.41</td><td>62.82</td><td>56.46</td><td>92.38</td><td>78.47</td><td>85.21</td><td>65.57</td><td>81.61</td><td>61.95</td><td>61.64</td><td>46.07</td><td>70.02</td><td>62.49</td><td>36.89</td><td>56.45</td><td>TRUE</td><td>TRUE</td></tr>\n",
       "\t<tr><td>105</td><td>59.45</td><td>66.16</td><td>54.62</td><td>57.56</td><td>72.21</td><td>66.32</td><td>75.91</td><td>50.21</td><td>68.71</td><td>56.61</td><td>41.87</td><td>51.28</td><td>74.13</td><td>59.83</td><td>55.73</td><td>40.54</td><td>TRUE</td><td>TRUE</td></tr>\n",
       "\t<tr><td> 36</td><td>79.93</td><td>88.01</td><td>77.07</td><td>74.71</td><td>91.17</td><td>94.88</td><td>91.84</td><td>74.16</td><td>91.56</td><td>80.30</td><td>67.85</td><td>68.58</td><td>93.79</td><td>78.63</td><td>58.23</td><td>68.19</td><td>TRUE</td><td>TRUE</td></tr>\n",
       "\t<tr><td>143</td><td>44.25</td><td>54.20</td><td>46.20</td><td>32.34</td><td>66.70</td><td>55.90</td><td>46.54</td><td>47.67</td><td>58.51</td><td>30.33</td><td>39.95</td><td>56.00</td><td>19.40</td><td>50.77</td><td>36.76</td><td>22.42</td><td>TRUE</td><td>TRUE</td></tr>\n",
       "\t<tr><td>154</td><td>46.58</td><td>44.86</td><td>48.63</td><td>46.24</td><td>55.91</td><td>30.89</td><td>40.36</td><td>52.27</td><td>66.72</td><td>36.98</td><td>33.67</td><td>57.17</td><td>69.13</td><td>50.94</td><td>35.03</td><td>29.85</td><td>TRUE</td><td>TRUE</td></tr>\n",
       "\t<tr><td> 69</td><td>67.71</td><td>80.42</td><td>69.13</td><td>53.59</td><td>91.56</td><td>82.05</td><td>86.87</td><td>61.20</td><td>94.69</td><td>74.48</td><td>49.48</td><td>57.87</td><td>53.29</td><td>70.34</td><td>38.38</td><td>52.35</td><td>TRUE</td><td>TRUE</td></tr>\n",
       "\t<tr><td>168</td><td>32.39</td><td>28.96</td><td>33.29</td><td>34.91</td><td>36.38</td><td>21.97</td><td>21.13</td><td>36.37</td><td>38.48</td><td>27.79</td><td>18.21</td><td>48.68</td><td>56.58</td><td>29.20</td><td>30.39</td><td>23.47</td><td>TRUE</td><td>TRUE</td></tr>\n",
       "\t<tr><td>141</td><td>48.89</td><td>63.31</td><td>48.66</td><td>34.69</td><td>74.23</td><td>63.23</td><td>60.94</td><td>54.82</td><td>60.98</td><td>29.20</td><td>45.09</td><td>59.38</td><td>22.02</td><td>55.11</td><td>38.55</td><td>23.10</td><td>TRUE</td><td>TRUE</td></tr>\n",
       "\t<tr><td>164</td><td>37.97</td><td>56.86</td><td>35.38</td><td>21.67</td><td>60.12</td><td>54.29</td><td>70.65</td><td>42.38</td><td>42.40</td><td>30.58</td><td>34.27</td><td>34.28</td><td>20.36</td><td>36.70</td><td> 5.20</td><td>24.44</td><td>TRUE</td><td>TRUE</td></tr>\n",
       "\t<tr><td>  1</td><td>90.53</td><td>91.18</td><td>90.79</td><td>89.61</td><td>93.87</td><td>98.79</td><td>91.31</td><td>80.76</td><td>98.69</td><td>96.25</td><td>88.44</td><td>79.78</td><td>95.63</td><td>88.77</td><td>90.78</td><td>83.26</td><td>TRUE</td><td>TRUE</td></tr>\n",
       "\t<tr><td> 64</td><td>70.85</td><td>79.02</td><td>71.16</td><td>62.36</td><td>85.50</td><td>83.44</td><td>83.89</td><td>63.25</td><td>74.73</td><td>82.22</td><td>63.24</td><td>64.46</td><td>85.49</td><td>63.10</td><td>41.77</td><td>59.06</td><td>TRUE</td><td>TRUE</td></tr>\n",
       "\t<tr><td> 75</td><td>66.15</td><td>68.20</td><td>62.45</td><td>67.78</td><td>73.34</td><td>71.66</td><td>80.32</td><td>47.49</td><td>79.84</td><td>65.67</td><td>49.76</td><td>54.55</td><td>89.48</td><td>71.72</td><td>57.10</td><td>52.82</td><td>TRUE</td><td>TRUE</td></tr>\n",
       "\t<tr><td>125</td><td>47.13</td><td>44.10</td><td>46.95</td><td>50.33</td><td>57.05</td><td>41.28</td><td>29.44</td><td>48.61</td><td>55.42</td><td>27.79</td><td>44.15</td><td>60.44</td><td>73.29</td><td>52.01</td><td>46.61</td><td>29.40</td><td>TRUE</td><td>TRUE</td></tr>\n",
       "\t<tr><td> 86</td><td>65.13</td><td>75.15</td><td>61.19</td><td>59.06</td><td>77.30</td><td>83.87</td><td>80.99</td><td>58.45</td><td>69.87</td><td>65.24</td><td>49.51</td><td>60.15</td><td>77.00</td><td>60.99</td><td>53.60</td><td>44.64</td><td>TRUE</td><td>TRUE</td></tr>\n",
       "\t<tr><td> 27</td><td>82.26</td><td>92.60</td><td>83.01</td><td>71.16</td><td>95.39</td><td>98.89</td><td>93.62</td><td>82.51</td><td>89.83</td><td>83.35</td><td>87.47</td><td>71.39</td><td>64.30</td><td>88.45</td><td>65.15</td><td>66.72</td><td>TRUE</td><td>TRUE</td></tr>\n",
       "\t<tr><td> 81</td><td>63.98</td><td>76.05</td><td>61.00</td><td>54.90</td><td>84.32</td><td>79.66</td><td>83.72</td><td>56.48</td><td>68.71</td><td>62.92</td><td>61.11</td><td>51.25</td><td>76.94</td><td>62.43</td><td>41.95</td><td>38.29</td><td>TRUE</td><td>TRUE</td></tr>\n",
       "\t<tr><td>144</td><td>48.89</td><td>52.80</td><td>54.34</td><td>39.54</td><td>74.38</td><td>56.89</td><td>44.24</td><td>35.66</td><td>68.75</td><td>47.66</td><td>44.92</td><td>56.01</td><td>46.80</td><td>50.00</td><td>28.36</td><td>32.99</td><td>TRUE</td><td>TRUE</td></tr>\n",
       "\t<tr><td>102</td><td>57.05</td><td>78.17</td><td>50.37</td><td>42.62</td><td>91.17</td><td>80.63</td><td>80.73</td><td>60.17</td><td>73.60</td><td>37.21</td><td>57.78</td><td>32.89</td><td>35.15</td><td>63.44</td><td>24.89</td><td>46.99</td><td>TRUE</td><td>TRUE</td></tr>\n",
       "\t<tr><td> 30</td><td>79.96</td><td>89.24</td><td>75.67</td><td>74.96</td><td>95.15</td><td>89.88</td><td>93.06</td><td>78.88</td><td>89.43</td><td>69.12</td><td>80.28</td><td>63.87</td><td>94.80</td><td>78.05</td><td>75.50</td><td>51.50</td><td>TRUE</td><td>TRUE</td></tr>\n",
       "\t<tr><td>126</td><td>54.08</td><td>54.01</td><td>57.65</td><td>50.59</td><td>66.19</td><td>55.23</td><td>44.42</td><td>50.21</td><td>60.96</td><td>55.47</td><td>52.18</td><td>61.98</td><td>60.94</td><td>53.10</td><td>57.41</td><td>30.90</td><td>TRUE</td><td>TRUE</td></tr>\n",
       "\t<tr><td> 25</td><td>83.02</td><td>87.77</td><td>81.22</td><td>80.07</td><td>96.34</td><td>90.46</td><td>89.62</td><td>74.65</td><td>91.26</td><td>81.27</td><td>79.68</td><td>72.67</td><td>96.13</td><td>72.63</td><td>79.74</td><td>71.78</td><td>TRUE</td><td>TRUE</td></tr>\n",
       "\t<tr><td> 78</td><td>66.45</td><td>83.38</td><td>61.98</td><td>54.01</td><td>94.83</td><td>83.59</td><td>90.46</td><td>64.64</td><td>70.86</td><td>62.24</td><td>69.04</td><td>45.77</td><td>50.86</td><td>61.19</td><td>40.63</td><td>63.34</td><td>TRUE</td><td>TRUE</td></tr>\n",
       "\t<tr><td>129</td><td>47.46</td><td>42.28</td><td>43.51</td><td>56.60</td><td>48.33</td><td>41.90</td><td>38.75</td><td>40.14</td><td>74.40</td><td>30.83</td><td>27.43</td><td>41.37</td><td>81.08</td><td>57.67</td><td>59.96</td><td>27.70</td><td>TRUE</td><td>TRUE</td></tr>\n",
       "\t<tr><td>123</td><td>54.34</td><td>67.05</td><td>53.59</td><td>42.39</td><td>74.20</td><td>64.51</td><td>66.93</td><td>62.58</td><td>53.26</td><td>48.73</td><td>51.75</td><td>60.60</td><td>45.60</td><td>58.42</td><td>33.21</td><td>32.32</td><td>TRUE</td><td>TRUE</td></tr>\n",
       "\t<tr><td>⋮</td><td>⋮</td><td>⋮</td><td>⋮</td><td>⋮</td><td>⋮</td><td>⋮</td><td>⋮</td><td>⋮</td><td>⋮</td><td>⋮</td><td>⋮</td><td>⋮</td><td>⋮</td><td>⋮</td><td>⋮</td><td>⋮</td><td>⋮</td><td>⋮</td></tr>\n",
       "\t<tr><td> 56</td><td>71.89</td><td>79.38</td><td>69.84</td><td>66.44</td><td>88.35</td><td>81.83</td><td>88.12</td><td>59.23</td><td>90.63</td><td>76.71</td><td>49.96</td><td>62.05</td><td>77.12</td><td>69.74</td><td>50.87</td><td>68.04</td><td>FALSE</td><td>TRUE</td></tr>\n",
       "\t<tr><td> 81</td><td>63.19</td><td>83.38</td><td>57.98</td><td>48.21</td><td>91.25</td><td>94.06</td><td>89.42</td><td>58.78</td><td>82.44</td><td>55.47</td><td>55.28</td><td>38.73</td><td>45.40</td><td>68.77</td><td>33.82</td><td>44.87</td><td>FALSE</td><td>TRUE</td></tr>\n",
       "\t<tr><td> 12</td><td>86.65</td><td>89.32</td><td>87.27</td><td>83.38</td><td>92.87</td><td>96.17</td><td>90.05</td><td>78.18</td><td>93.23</td><td>95.24</td><td>82.54</td><td>78.07</td><td>93.30</td><td>85.26</td><td>76.88</td><td>78.06</td><td>FALSE</td><td>TRUE</td></tr>\n",
       "\t<tr><td> 16</td><td>86.89</td><td>89.12</td><td>87.75</td><td>83.79</td><td>92.94</td><td>94.28</td><td>89.14</td><td>80.10</td><td>92.20</td><td>97.69</td><td>82.02</td><td>79.10</td><td>94.60</td><td>86.84</td><td>75.20</td><td>78.52</td><td>FALSE</td><td>TRUE</td></tr>\n",
       "\t<tr><td> 19</td><td>85.42</td><td>87.59</td><td>82.68</td><td>86.00</td><td>93.02</td><td>93.87</td><td>92.71</td><td>70.75</td><td>93.05</td><td>89.04</td><td>74.66</td><td>73.98</td><td>95.94</td><td>84.53</td><td>75.16</td><td>88.36</td><td>FALSE</td><td>TRUE</td></tr>\n",
       "\t<tr><td> 19</td><td>85.21</td><td>87.42</td><td>82.39</td><td>85.83</td><td>93.07</td><td>93.44</td><td>92.01</td><td>71.15</td><td>92.69</td><td>88.48</td><td>74.07</td><td>74.32</td><td>95.31</td><td>84.53</td><td>75.30</td><td>88.17</td><td>FALSE</td><td>TRUE</td></tr>\n",
       "\t<tr><td> 20</td><td>84.99</td><td>87.28</td><td>83.27</td><td>84.42</td><td>93.10</td><td>93.35</td><td>91.80</td><td>70.87</td><td>93.39</td><td>91.01</td><td>74.13</td><td>74.55</td><td>92.26</td><td>84.93</td><td>72.34</td><td>88.15</td><td>FALSE</td><td>TRUE</td></tr>\n",
       "\t<tr><td> 23</td><td>85.14</td><td>87.22</td><td>83.95</td><td>84.26</td><td>93.13</td><td>93.26</td><td>91.73</td><td>70.75</td><td>93.27</td><td>93.80</td><td>73.80</td><td>74.91</td><td>91.23</td><td>84.48</td><td>73.12</td><td>88.20</td><td>FALSE</td><td>TRUE</td></tr>\n",
       "\t<tr><td> 24</td><td>85.04</td><td>87.42</td><td>84.15</td><td>83.54</td><td>93.18</td><td>94.01</td><td>91.31</td><td>71.19</td><td>92.74</td><td>95.14</td><td>73.39</td><td>75.32</td><td>88.88</td><td>84.14</td><td>73.02</td><td>88.12</td><td>FALSE</td><td>TRUE</td></tr>\n",
       "\t<tr><td> 38</td><td>77.64</td><td>84.48</td><td>70.93</td><td>77.52</td><td>89.20</td><td>95.08</td><td>89.23</td><td>64.42</td><td>86.70</td><td>64.21</td><td>70.45</td><td>62.34</td><td>95.06</td><td>77.64</td><td>82.72</td><td>54.67</td><td>FALSE</td><td>TRUE</td></tr>\n",
       "\t<tr><td> 39</td><td>77.67</td><td>84.17</td><td>70.81</td><td>78.02</td><td>89.30</td><td>93.78</td><td>88.51</td><td>65.10</td><td>86.79</td><td>63.67</td><td>70.30</td><td>62.46</td><td>95.06</td><td>78.07</td><td>82.48</td><td>56.46</td><td>FALSE</td><td>TRUE</td></tr>\n",
       "\t<tr><td>108</td><td>59.89</td><td>85.47</td><td>57.32</td><td>36.88</td><td>89.70</td><td>93.73</td><td>93.00</td><td>65.44</td><td>93.62</td><td>53.49</td><td>49.12</td><td>33.06</td><td>24.50</td><td>60.02</td><td>26.53</td><td>36.46</td><td>FALSE</td><td>TRUE</td></tr>\n",
       "\t<tr><td>103</td><td>61.50</td><td>85.80</td><td>57.62</td><td>41.07</td><td>89.97</td><td>92.78</td><td>92.46</td><td>67.97</td><td>92.51</td><td>56.51</td><td>48.62</td><td>32.84</td><td>37.84</td><td>60.41</td><td>28.18</td><td>37.86</td><td>FALSE</td><td>TRUE</td></tr>\n",
       "\t<tr><td> 99</td><td>63.99</td><td>86.05</td><td>59.60</td><td>46.30</td><td>90.45</td><td>91.68</td><td>91.80</td><td>70.28</td><td>93.26</td><td>61.84</td><td>48.48</td><td>34.84</td><td>50.81</td><td>62.48</td><td>30.22</td><td>41.68</td><td>FALSE</td><td>TRUE</td></tr>\n",
       "\t<tr><td> 90</td><td>63.82</td><td>74.66</td><td>65.38</td><td>51.44</td><td>87.37</td><td>79.54</td><td>83.53</td><td>48.18</td><td>76.73</td><td>68.96</td><td>54.89</td><td>60.92</td><td>52.87</td><td>60.59</td><td>51.34</td><td>40.97</td><td>FALSE</td><td>TRUE</td></tr>\n",
       "\t<tr><td> 86</td><td>63.43</td><td>78.04</td><td>60.71</td><td>51.53</td><td>84.45</td><td>82.19</td><td>82.11</td><td>63.41</td><td>85.43</td><td>45.85</td><td>59.20</td><td>52.38</td><td>46.54</td><td>63.97</td><td>56.46</td><td>39.15</td><td>FALSE</td><td>TRUE</td></tr>\n",
       "\t<tr><td> 84</td><td>65.18</td><td>79.22</td><td>64.56</td><td>51.77</td><td>85.29</td><td>84.22</td><td>83.74</td><td>63.62</td><td>86.23</td><td>57.37</td><td>60.06</td><td>54.60</td><td>46.54</td><td>63.88</td><td>55.49</td><td>41.18</td><td>FALSE</td><td>TRUE</td></tr>\n",
       "\t<tr><td> 92</td><td>62.07</td><td>76.50</td><td>56.97</td><td>52.73</td><td>90.33</td><td>69.58</td><td>85.70</td><td>60.38</td><td>77.71</td><td>48.77</td><td>56.34</td><td>45.07</td><td>61.82</td><td>54.19</td><td>43.08</td><td>51.83</td><td>FALSE</td><td>TRUE</td></tr>\n",
       "\t<tr><td> 92</td><td>63.03</td><td>77.07</td><td>60.16</td><td>51.85</td><td>90.76</td><td>71.19</td><td>86.46</td><td>59.87</td><td>81.69</td><td>52.45</td><td>59.64</td><td>46.86</td><td>60.80</td><td>53.13</td><td>41.54</td><td>51.92</td><td>FALSE</td><td>TRUE</td></tr>\n",
       "\t<tr><td> 91</td><td>64.36</td><td>77.05</td><td>63.10</td><td>52.94</td><td>91.22</td><td>71.28</td><td>86.77</td><td>58.91</td><td>83.32</td><td>61.18</td><td>61.40</td><td>46.48</td><td>62.61</td><td>54.86</td><td>40.86</td><td>53.41</td><td>FALSE</td><td>TRUE</td></tr>\n",
       "\t<tr><td>159</td><td>40.22</td><td>55.90</td><td>37.23</td><td>27.52</td><td>62.73</td><td>45.25</td><td>66.76</td><td>48.85</td><td>40.88</td><td>39.43</td><td>34.02</td><td>34.59</td><td>34.16</td><td>38.11</td><td>11.45</td><td>26.36</td><td>FALSE</td><td>TRUE</td></tr>\n",
       "\t<tr><td>133</td><td>49.64</td><td>49.12</td><td>49.87</td><td>49.94</td><td>58.72</td><td>48.90</td><td>43.08</td><td>45.76</td><td>61.58</td><td>36.23</td><td>41.93</td><td>59.72</td><td>69.52</td><td>55.33</td><td>43.42</td><td>31.51</td><td>FALSE</td><td>TRUE</td></tr>\n",
       "\t<tr><td>130</td><td>50.43</td><td>49.86</td><td>51.40</td><td>50.03</td><td>59.57</td><td>50.81</td><td>45.09</td><td>43.98</td><td>60.40</td><td>42.79</td><td>42.43</td><td>59.98</td><td>66.93</td><td>56.34</td><td>45.00</td><td>31.84</td><td>FALSE</td><td>TRUE</td></tr>\n",
       "\t<tr><td>131</td><td>51.01</td><td>50.43</td><td>51.98</td><td>50.63</td><td>60.52</td><td>51.30</td><td>46.69</td><td>43.22</td><td>61.18</td><td>43.48</td><td>43.24</td><td>60.00</td><td>68.18</td><td>55.51</td><td>46.76</td><td>32.06</td><td>FALSE</td><td>TRUE</td></tr>\n",
       "\t<tr><td>133</td><td>51.21</td><td>50.99</td><td>53.48</td><td>49.15</td><td>61.26</td><td>49.79</td><td>47.95</td><td>44.96</td><td>62.32</td><td>48.19</td><td>43.33</td><td>60.09</td><td>62.78</td><td>55.31</td><td>46.25</td><td>32.28</td><td>FALSE</td><td>TRUE</td></tr>\n",
       "\t<tr><td>131</td><td>51.66</td><td>51.30</td><td>54.70</td><td>48.98</td><td>61.75</td><td>49.82</td><td>48.17</td><td>45.45</td><td>63.20</td><td>52.22</td><td>42.75</td><td>60.63</td><td>63.54</td><td>56.47</td><td>42.92</td><td>32.99</td><td>FALSE</td><td>TRUE</td></tr>\n",
       "\t<tr><td>137</td><td>44.29</td><td>48.11</td><td>46.11</td><td>38.64</td><td>44.53</td><td>57.40</td><td>48.55</td><td>41.94</td><td>77.41</td><td>19.28</td><td>28.85</td><td>58.91</td><td>53.36</td><td>56.03</td><td>19.02</td><td>26.12</td><td>FALSE</td><td>TRUE</td></tr>\n",
       "\t<tr><td>125</td><td>49.07</td><td>52.16</td><td>54.10</td><td>40.94</td><td>54.24</td><td>59.72</td><td>49.91</td><td>44.76</td><td>80.29</td><td>42.44</td><td>34.55</td><td>59.10</td><td>58.06</td><td>56.97</td><td>21.23</td><td>27.51</td><td>FALSE</td><td>TRUE</td></tr>\n",
       "\t<tr><td>130</td><td>51.18</td><td>55.28</td><td>56.35</td><td>41.90</td><td>61.09</td><td>62.57</td><td>51.55</td><td>45.91</td><td>76.98</td><td>51.34</td><td>37.95</td><td>59.12</td><td>57.10</td><td>56.52</td><td>24.09</td><td>29.90</td><td>FALSE</td><td>TRUE</td></tr>\n",
       "\t<tr><td>131</td><td>52.22</td><td>54.59</td><td>58.15</td><td>43.94</td><td>62.96</td><td>61.00</td><td>51.06</td><td>43.32</td><td>78.88</td><td>56.08</td><td>37.43</td><td>60.20</td><td>56.93</td><td>57.14</td><td>29.77</td><td>31.92</td><td>FALSE</td><td>TRUE</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A tibble: 2028 × 19\n",
       "\\begin{tabular}{lllllllllllllllllll}\n",
       " rank\\_score\\_spi & score\\_spi & score\\_bhn & score\\_fow & score\\_opp & score\\_nbmc & score\\_ws & score\\_sh & score\\_ps & score\\_abk & score\\_aic & score\\_hw & score\\_eq & score\\_pr & score\\_pfc & score\\_incl & score\\_aae & is\\_train & x\\\\\n",
       " <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <lgl> & <lgl>\\\\\n",
       "\\hline\n",
       "\t  80 & 67.59 & 79.16 & 65.40 & 58.22 & 86.67 & 86.44 & 87.69 & 55.85 & 74.20 & 74.19 & 53.55 & 59.66 & 81.60 & 60.29 & 40.24 & 50.73 & TRUE & TRUE\\\\\n",
       "\t  97 & 60.10 & 74.55 & 51.25 & 54.49 & 72.88 & 83.35 & 77.17 & 64.81 & 47.04 & 37.15 & 64.58 & 56.22 & 71.05 & 64.77 & 56.12 & 26.03 & TRUE & TRUE\\\\\n",
       "\t  46 & 73.96 & 81.88 & 70.69 & 69.32 & 86.33 & 88.07 & 89.59 & 63.55 & 89.07 & 68.14 & 61.41 & 64.13 & 90.28 & 67.65 & 68.48 & 50.87 & TRUE & TRUE\\\\\n",
       "\t  84 & 62.86 & 79.45 & 61.22 & 47.92 & 83.91 & 77.71 & 85.11 & 71.08 & 65.15 & 51.25 & 62.00 & 66.47 & 61.56 & 56.51 & 48.70 & 24.90 & TRUE & TRUE\\\\\n",
       "\t  99 & 61.43 & 77.84 & 57.63 & 48.83 & 87.72 & 78.15 & 86.61 & 58.87 & 55.79 & 78.17 & 45.35 & 51.22 & 60.41 & 58.62 & 35.57 & 40.72 & TRUE & TRUE\\\\\n",
       "\t 150 & 45.57 & 47.15 & 45.21 & 44.34 & 54.66 & 47.82 & 36.59 & 49.53 & 50.36 & 33.84 & 36.99 & 59.66 & 69.20 & 40.61 & 41.81 & 25.72 & TRUE & TRUE\\\\\n",
       "\t  74 & 66.56 & 80.41 & 62.82 & 56.46 & 92.38 & 78.47 & 85.21 & 65.57 & 81.61 & 61.95 & 61.64 & 46.07 & 70.02 & 62.49 & 36.89 & 56.45 & TRUE & TRUE\\\\\n",
       "\t 105 & 59.45 & 66.16 & 54.62 & 57.56 & 72.21 & 66.32 & 75.91 & 50.21 & 68.71 & 56.61 & 41.87 & 51.28 & 74.13 & 59.83 & 55.73 & 40.54 & TRUE & TRUE\\\\\n",
       "\t  36 & 79.93 & 88.01 & 77.07 & 74.71 & 91.17 & 94.88 & 91.84 & 74.16 & 91.56 & 80.30 & 67.85 & 68.58 & 93.79 & 78.63 & 58.23 & 68.19 & TRUE & TRUE\\\\\n",
       "\t 143 & 44.25 & 54.20 & 46.20 & 32.34 & 66.70 & 55.90 & 46.54 & 47.67 & 58.51 & 30.33 & 39.95 & 56.00 & 19.40 & 50.77 & 36.76 & 22.42 & TRUE & TRUE\\\\\n",
       "\t 154 & 46.58 & 44.86 & 48.63 & 46.24 & 55.91 & 30.89 & 40.36 & 52.27 & 66.72 & 36.98 & 33.67 & 57.17 & 69.13 & 50.94 & 35.03 & 29.85 & TRUE & TRUE\\\\\n",
       "\t  69 & 67.71 & 80.42 & 69.13 & 53.59 & 91.56 & 82.05 & 86.87 & 61.20 & 94.69 & 74.48 & 49.48 & 57.87 & 53.29 & 70.34 & 38.38 & 52.35 & TRUE & TRUE\\\\\n",
       "\t 168 & 32.39 & 28.96 & 33.29 & 34.91 & 36.38 & 21.97 & 21.13 & 36.37 & 38.48 & 27.79 & 18.21 & 48.68 & 56.58 & 29.20 & 30.39 & 23.47 & TRUE & TRUE\\\\\n",
       "\t 141 & 48.89 & 63.31 & 48.66 & 34.69 & 74.23 & 63.23 & 60.94 & 54.82 & 60.98 & 29.20 & 45.09 & 59.38 & 22.02 & 55.11 & 38.55 & 23.10 & TRUE & TRUE\\\\\n",
       "\t 164 & 37.97 & 56.86 & 35.38 & 21.67 & 60.12 & 54.29 & 70.65 & 42.38 & 42.40 & 30.58 & 34.27 & 34.28 & 20.36 & 36.70 &  5.20 & 24.44 & TRUE & TRUE\\\\\n",
       "\t   1 & 90.53 & 91.18 & 90.79 & 89.61 & 93.87 & 98.79 & 91.31 & 80.76 & 98.69 & 96.25 & 88.44 & 79.78 & 95.63 & 88.77 & 90.78 & 83.26 & TRUE & TRUE\\\\\n",
       "\t  64 & 70.85 & 79.02 & 71.16 & 62.36 & 85.50 & 83.44 & 83.89 & 63.25 & 74.73 & 82.22 & 63.24 & 64.46 & 85.49 & 63.10 & 41.77 & 59.06 & TRUE & TRUE\\\\\n",
       "\t  75 & 66.15 & 68.20 & 62.45 & 67.78 & 73.34 & 71.66 & 80.32 & 47.49 & 79.84 & 65.67 & 49.76 & 54.55 & 89.48 & 71.72 & 57.10 & 52.82 & TRUE & TRUE\\\\\n",
       "\t 125 & 47.13 & 44.10 & 46.95 & 50.33 & 57.05 & 41.28 & 29.44 & 48.61 & 55.42 & 27.79 & 44.15 & 60.44 & 73.29 & 52.01 & 46.61 & 29.40 & TRUE & TRUE\\\\\n",
       "\t  86 & 65.13 & 75.15 & 61.19 & 59.06 & 77.30 & 83.87 & 80.99 & 58.45 & 69.87 & 65.24 & 49.51 & 60.15 & 77.00 & 60.99 & 53.60 & 44.64 & TRUE & TRUE\\\\\n",
       "\t  27 & 82.26 & 92.60 & 83.01 & 71.16 & 95.39 & 98.89 & 93.62 & 82.51 & 89.83 & 83.35 & 87.47 & 71.39 & 64.30 & 88.45 & 65.15 & 66.72 & TRUE & TRUE\\\\\n",
       "\t  81 & 63.98 & 76.05 & 61.00 & 54.90 & 84.32 & 79.66 & 83.72 & 56.48 & 68.71 & 62.92 & 61.11 & 51.25 & 76.94 & 62.43 & 41.95 & 38.29 & TRUE & TRUE\\\\\n",
       "\t 144 & 48.89 & 52.80 & 54.34 & 39.54 & 74.38 & 56.89 & 44.24 & 35.66 & 68.75 & 47.66 & 44.92 & 56.01 & 46.80 & 50.00 & 28.36 & 32.99 & TRUE & TRUE\\\\\n",
       "\t 102 & 57.05 & 78.17 & 50.37 & 42.62 & 91.17 & 80.63 & 80.73 & 60.17 & 73.60 & 37.21 & 57.78 & 32.89 & 35.15 & 63.44 & 24.89 & 46.99 & TRUE & TRUE\\\\\n",
       "\t  30 & 79.96 & 89.24 & 75.67 & 74.96 & 95.15 & 89.88 & 93.06 & 78.88 & 89.43 & 69.12 & 80.28 & 63.87 & 94.80 & 78.05 & 75.50 & 51.50 & TRUE & TRUE\\\\\n",
       "\t 126 & 54.08 & 54.01 & 57.65 & 50.59 & 66.19 & 55.23 & 44.42 & 50.21 & 60.96 & 55.47 & 52.18 & 61.98 & 60.94 & 53.10 & 57.41 & 30.90 & TRUE & TRUE\\\\\n",
       "\t  25 & 83.02 & 87.77 & 81.22 & 80.07 & 96.34 & 90.46 & 89.62 & 74.65 & 91.26 & 81.27 & 79.68 & 72.67 & 96.13 & 72.63 & 79.74 & 71.78 & TRUE & TRUE\\\\\n",
       "\t  78 & 66.45 & 83.38 & 61.98 & 54.01 & 94.83 & 83.59 & 90.46 & 64.64 & 70.86 & 62.24 & 69.04 & 45.77 & 50.86 & 61.19 & 40.63 & 63.34 & TRUE & TRUE\\\\\n",
       "\t 129 & 47.46 & 42.28 & 43.51 & 56.60 & 48.33 & 41.90 & 38.75 & 40.14 & 74.40 & 30.83 & 27.43 & 41.37 & 81.08 & 57.67 & 59.96 & 27.70 & TRUE & TRUE\\\\\n",
       "\t 123 & 54.34 & 67.05 & 53.59 & 42.39 & 74.20 & 64.51 & 66.93 & 62.58 & 53.26 & 48.73 & 51.75 & 60.60 & 45.60 & 58.42 & 33.21 & 32.32 & TRUE & TRUE\\\\\n",
       "\t ⋮ & ⋮ & ⋮ & ⋮ & ⋮ & ⋮ & ⋮ & ⋮ & ⋮ & ⋮ & ⋮ & ⋮ & ⋮ & ⋮ & ⋮ & ⋮ & ⋮ & ⋮ & ⋮\\\\\n",
       "\t  56 & 71.89 & 79.38 & 69.84 & 66.44 & 88.35 & 81.83 & 88.12 & 59.23 & 90.63 & 76.71 & 49.96 & 62.05 & 77.12 & 69.74 & 50.87 & 68.04 & FALSE & TRUE\\\\\n",
       "\t  81 & 63.19 & 83.38 & 57.98 & 48.21 & 91.25 & 94.06 & 89.42 & 58.78 & 82.44 & 55.47 & 55.28 & 38.73 & 45.40 & 68.77 & 33.82 & 44.87 & FALSE & TRUE\\\\\n",
       "\t  12 & 86.65 & 89.32 & 87.27 & 83.38 & 92.87 & 96.17 & 90.05 & 78.18 & 93.23 & 95.24 & 82.54 & 78.07 & 93.30 & 85.26 & 76.88 & 78.06 & FALSE & TRUE\\\\\n",
       "\t  16 & 86.89 & 89.12 & 87.75 & 83.79 & 92.94 & 94.28 & 89.14 & 80.10 & 92.20 & 97.69 & 82.02 & 79.10 & 94.60 & 86.84 & 75.20 & 78.52 & FALSE & TRUE\\\\\n",
       "\t  19 & 85.42 & 87.59 & 82.68 & 86.00 & 93.02 & 93.87 & 92.71 & 70.75 & 93.05 & 89.04 & 74.66 & 73.98 & 95.94 & 84.53 & 75.16 & 88.36 & FALSE & TRUE\\\\\n",
       "\t  19 & 85.21 & 87.42 & 82.39 & 85.83 & 93.07 & 93.44 & 92.01 & 71.15 & 92.69 & 88.48 & 74.07 & 74.32 & 95.31 & 84.53 & 75.30 & 88.17 & FALSE & TRUE\\\\\n",
       "\t  20 & 84.99 & 87.28 & 83.27 & 84.42 & 93.10 & 93.35 & 91.80 & 70.87 & 93.39 & 91.01 & 74.13 & 74.55 & 92.26 & 84.93 & 72.34 & 88.15 & FALSE & TRUE\\\\\n",
       "\t  23 & 85.14 & 87.22 & 83.95 & 84.26 & 93.13 & 93.26 & 91.73 & 70.75 & 93.27 & 93.80 & 73.80 & 74.91 & 91.23 & 84.48 & 73.12 & 88.20 & FALSE & TRUE\\\\\n",
       "\t  24 & 85.04 & 87.42 & 84.15 & 83.54 & 93.18 & 94.01 & 91.31 & 71.19 & 92.74 & 95.14 & 73.39 & 75.32 & 88.88 & 84.14 & 73.02 & 88.12 & FALSE & TRUE\\\\\n",
       "\t  38 & 77.64 & 84.48 & 70.93 & 77.52 & 89.20 & 95.08 & 89.23 & 64.42 & 86.70 & 64.21 & 70.45 & 62.34 & 95.06 & 77.64 & 82.72 & 54.67 & FALSE & TRUE\\\\\n",
       "\t  39 & 77.67 & 84.17 & 70.81 & 78.02 & 89.30 & 93.78 & 88.51 & 65.10 & 86.79 & 63.67 & 70.30 & 62.46 & 95.06 & 78.07 & 82.48 & 56.46 & FALSE & TRUE\\\\\n",
       "\t 108 & 59.89 & 85.47 & 57.32 & 36.88 & 89.70 & 93.73 & 93.00 & 65.44 & 93.62 & 53.49 & 49.12 & 33.06 & 24.50 & 60.02 & 26.53 & 36.46 & FALSE & TRUE\\\\\n",
       "\t 103 & 61.50 & 85.80 & 57.62 & 41.07 & 89.97 & 92.78 & 92.46 & 67.97 & 92.51 & 56.51 & 48.62 & 32.84 & 37.84 & 60.41 & 28.18 & 37.86 & FALSE & TRUE\\\\\n",
       "\t  99 & 63.99 & 86.05 & 59.60 & 46.30 & 90.45 & 91.68 & 91.80 & 70.28 & 93.26 & 61.84 & 48.48 & 34.84 & 50.81 & 62.48 & 30.22 & 41.68 & FALSE & TRUE\\\\\n",
       "\t  90 & 63.82 & 74.66 & 65.38 & 51.44 & 87.37 & 79.54 & 83.53 & 48.18 & 76.73 & 68.96 & 54.89 & 60.92 & 52.87 & 60.59 & 51.34 & 40.97 & FALSE & TRUE\\\\\n",
       "\t  86 & 63.43 & 78.04 & 60.71 & 51.53 & 84.45 & 82.19 & 82.11 & 63.41 & 85.43 & 45.85 & 59.20 & 52.38 & 46.54 & 63.97 & 56.46 & 39.15 & FALSE & TRUE\\\\\n",
       "\t  84 & 65.18 & 79.22 & 64.56 & 51.77 & 85.29 & 84.22 & 83.74 & 63.62 & 86.23 & 57.37 & 60.06 & 54.60 & 46.54 & 63.88 & 55.49 & 41.18 & FALSE & TRUE\\\\\n",
       "\t  92 & 62.07 & 76.50 & 56.97 & 52.73 & 90.33 & 69.58 & 85.70 & 60.38 & 77.71 & 48.77 & 56.34 & 45.07 & 61.82 & 54.19 & 43.08 & 51.83 & FALSE & TRUE\\\\\n",
       "\t  92 & 63.03 & 77.07 & 60.16 & 51.85 & 90.76 & 71.19 & 86.46 & 59.87 & 81.69 & 52.45 & 59.64 & 46.86 & 60.80 & 53.13 & 41.54 & 51.92 & FALSE & TRUE\\\\\n",
       "\t  91 & 64.36 & 77.05 & 63.10 & 52.94 & 91.22 & 71.28 & 86.77 & 58.91 & 83.32 & 61.18 & 61.40 & 46.48 & 62.61 & 54.86 & 40.86 & 53.41 & FALSE & TRUE\\\\\n",
       "\t 159 & 40.22 & 55.90 & 37.23 & 27.52 & 62.73 & 45.25 & 66.76 & 48.85 & 40.88 & 39.43 & 34.02 & 34.59 & 34.16 & 38.11 & 11.45 & 26.36 & FALSE & TRUE\\\\\n",
       "\t 133 & 49.64 & 49.12 & 49.87 & 49.94 & 58.72 & 48.90 & 43.08 & 45.76 & 61.58 & 36.23 & 41.93 & 59.72 & 69.52 & 55.33 & 43.42 & 31.51 & FALSE & TRUE\\\\\n",
       "\t 130 & 50.43 & 49.86 & 51.40 & 50.03 & 59.57 & 50.81 & 45.09 & 43.98 & 60.40 & 42.79 & 42.43 & 59.98 & 66.93 & 56.34 & 45.00 & 31.84 & FALSE & TRUE\\\\\n",
       "\t 131 & 51.01 & 50.43 & 51.98 & 50.63 & 60.52 & 51.30 & 46.69 & 43.22 & 61.18 & 43.48 & 43.24 & 60.00 & 68.18 & 55.51 & 46.76 & 32.06 & FALSE & TRUE\\\\\n",
       "\t 133 & 51.21 & 50.99 & 53.48 & 49.15 & 61.26 & 49.79 & 47.95 & 44.96 & 62.32 & 48.19 & 43.33 & 60.09 & 62.78 & 55.31 & 46.25 & 32.28 & FALSE & TRUE\\\\\n",
       "\t 131 & 51.66 & 51.30 & 54.70 & 48.98 & 61.75 & 49.82 & 48.17 & 45.45 & 63.20 & 52.22 & 42.75 & 60.63 & 63.54 & 56.47 & 42.92 & 32.99 & FALSE & TRUE\\\\\n",
       "\t 137 & 44.29 & 48.11 & 46.11 & 38.64 & 44.53 & 57.40 & 48.55 & 41.94 & 77.41 & 19.28 & 28.85 & 58.91 & 53.36 & 56.03 & 19.02 & 26.12 & FALSE & TRUE\\\\\n",
       "\t 125 & 49.07 & 52.16 & 54.10 & 40.94 & 54.24 & 59.72 & 49.91 & 44.76 & 80.29 & 42.44 & 34.55 & 59.10 & 58.06 & 56.97 & 21.23 & 27.51 & FALSE & TRUE\\\\\n",
       "\t 130 & 51.18 & 55.28 & 56.35 & 41.90 & 61.09 & 62.57 & 51.55 & 45.91 & 76.98 & 51.34 & 37.95 & 59.12 & 57.10 & 56.52 & 24.09 & 29.90 & FALSE & TRUE\\\\\n",
       "\t 131 & 52.22 & 54.59 & 58.15 & 43.94 & 62.96 & 61.00 & 51.06 & 43.32 & 78.88 & 56.08 & 37.43 & 60.20 & 56.93 & 57.14 & 29.77 & 31.92 & FALSE & TRUE\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A tibble: 2028 × 19\n",
       "\n",
       "| rank_score_spi &lt;dbl&gt; | score_spi &lt;dbl&gt; | score_bhn &lt;dbl&gt; | score_fow &lt;dbl&gt; | score_opp &lt;dbl&gt; | score_nbmc &lt;dbl&gt; | score_ws &lt;dbl&gt; | score_sh &lt;dbl&gt; | score_ps &lt;dbl&gt; | score_abk &lt;dbl&gt; | score_aic &lt;dbl&gt; | score_hw &lt;dbl&gt; | score_eq &lt;dbl&gt; | score_pr &lt;dbl&gt; | score_pfc &lt;dbl&gt; | score_incl &lt;dbl&gt; | score_aae &lt;dbl&gt; | is_train &lt;lgl&gt; | x &lt;lgl&gt; |\n",
       "|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|\n",
       "|  80 | 67.59 | 79.16 | 65.40 | 58.22 | 86.67 | 86.44 | 87.69 | 55.85 | 74.20 | 74.19 | 53.55 | 59.66 | 81.60 | 60.29 | 40.24 | 50.73 | TRUE | TRUE |\n",
       "|  97 | 60.10 | 74.55 | 51.25 | 54.49 | 72.88 | 83.35 | 77.17 | 64.81 | 47.04 | 37.15 | 64.58 | 56.22 | 71.05 | 64.77 | 56.12 | 26.03 | TRUE | TRUE |\n",
       "|  46 | 73.96 | 81.88 | 70.69 | 69.32 | 86.33 | 88.07 | 89.59 | 63.55 | 89.07 | 68.14 | 61.41 | 64.13 | 90.28 | 67.65 | 68.48 | 50.87 | TRUE | TRUE |\n",
       "|  84 | 62.86 | 79.45 | 61.22 | 47.92 | 83.91 | 77.71 | 85.11 | 71.08 | 65.15 | 51.25 | 62.00 | 66.47 | 61.56 | 56.51 | 48.70 | 24.90 | TRUE | TRUE |\n",
       "|  99 | 61.43 | 77.84 | 57.63 | 48.83 | 87.72 | 78.15 | 86.61 | 58.87 | 55.79 | 78.17 | 45.35 | 51.22 | 60.41 | 58.62 | 35.57 | 40.72 | TRUE | TRUE |\n",
       "| 150 | 45.57 | 47.15 | 45.21 | 44.34 | 54.66 | 47.82 | 36.59 | 49.53 | 50.36 | 33.84 | 36.99 | 59.66 | 69.20 | 40.61 | 41.81 | 25.72 | TRUE | TRUE |\n",
       "|  74 | 66.56 | 80.41 | 62.82 | 56.46 | 92.38 | 78.47 | 85.21 | 65.57 | 81.61 | 61.95 | 61.64 | 46.07 | 70.02 | 62.49 | 36.89 | 56.45 | TRUE | TRUE |\n",
       "| 105 | 59.45 | 66.16 | 54.62 | 57.56 | 72.21 | 66.32 | 75.91 | 50.21 | 68.71 | 56.61 | 41.87 | 51.28 | 74.13 | 59.83 | 55.73 | 40.54 | TRUE | TRUE |\n",
       "|  36 | 79.93 | 88.01 | 77.07 | 74.71 | 91.17 | 94.88 | 91.84 | 74.16 | 91.56 | 80.30 | 67.85 | 68.58 | 93.79 | 78.63 | 58.23 | 68.19 | TRUE | TRUE |\n",
       "| 143 | 44.25 | 54.20 | 46.20 | 32.34 | 66.70 | 55.90 | 46.54 | 47.67 | 58.51 | 30.33 | 39.95 | 56.00 | 19.40 | 50.77 | 36.76 | 22.42 | TRUE | TRUE |\n",
       "| 154 | 46.58 | 44.86 | 48.63 | 46.24 | 55.91 | 30.89 | 40.36 | 52.27 | 66.72 | 36.98 | 33.67 | 57.17 | 69.13 | 50.94 | 35.03 | 29.85 | TRUE | TRUE |\n",
       "|  69 | 67.71 | 80.42 | 69.13 | 53.59 | 91.56 | 82.05 | 86.87 | 61.20 | 94.69 | 74.48 | 49.48 | 57.87 | 53.29 | 70.34 | 38.38 | 52.35 | TRUE | TRUE |\n",
       "| 168 | 32.39 | 28.96 | 33.29 | 34.91 | 36.38 | 21.97 | 21.13 | 36.37 | 38.48 | 27.79 | 18.21 | 48.68 | 56.58 | 29.20 | 30.39 | 23.47 | TRUE | TRUE |\n",
       "| 141 | 48.89 | 63.31 | 48.66 | 34.69 | 74.23 | 63.23 | 60.94 | 54.82 | 60.98 | 29.20 | 45.09 | 59.38 | 22.02 | 55.11 | 38.55 | 23.10 | TRUE | TRUE |\n",
       "| 164 | 37.97 | 56.86 | 35.38 | 21.67 | 60.12 | 54.29 | 70.65 | 42.38 | 42.40 | 30.58 | 34.27 | 34.28 | 20.36 | 36.70 |  5.20 | 24.44 | TRUE | TRUE |\n",
       "|   1 | 90.53 | 91.18 | 90.79 | 89.61 | 93.87 | 98.79 | 91.31 | 80.76 | 98.69 | 96.25 | 88.44 | 79.78 | 95.63 | 88.77 | 90.78 | 83.26 | TRUE | TRUE |\n",
       "|  64 | 70.85 | 79.02 | 71.16 | 62.36 | 85.50 | 83.44 | 83.89 | 63.25 | 74.73 | 82.22 | 63.24 | 64.46 | 85.49 | 63.10 | 41.77 | 59.06 | TRUE | TRUE |\n",
       "|  75 | 66.15 | 68.20 | 62.45 | 67.78 | 73.34 | 71.66 | 80.32 | 47.49 | 79.84 | 65.67 | 49.76 | 54.55 | 89.48 | 71.72 | 57.10 | 52.82 | TRUE | TRUE |\n",
       "| 125 | 47.13 | 44.10 | 46.95 | 50.33 | 57.05 | 41.28 | 29.44 | 48.61 | 55.42 | 27.79 | 44.15 | 60.44 | 73.29 | 52.01 | 46.61 | 29.40 | TRUE | TRUE |\n",
       "|  86 | 65.13 | 75.15 | 61.19 | 59.06 | 77.30 | 83.87 | 80.99 | 58.45 | 69.87 | 65.24 | 49.51 | 60.15 | 77.00 | 60.99 | 53.60 | 44.64 | TRUE | TRUE |\n",
       "|  27 | 82.26 | 92.60 | 83.01 | 71.16 | 95.39 | 98.89 | 93.62 | 82.51 | 89.83 | 83.35 | 87.47 | 71.39 | 64.30 | 88.45 | 65.15 | 66.72 | TRUE | TRUE |\n",
       "|  81 | 63.98 | 76.05 | 61.00 | 54.90 | 84.32 | 79.66 | 83.72 | 56.48 | 68.71 | 62.92 | 61.11 | 51.25 | 76.94 | 62.43 | 41.95 | 38.29 | TRUE | TRUE |\n",
       "| 144 | 48.89 | 52.80 | 54.34 | 39.54 | 74.38 | 56.89 | 44.24 | 35.66 | 68.75 | 47.66 | 44.92 | 56.01 | 46.80 | 50.00 | 28.36 | 32.99 | TRUE | TRUE |\n",
       "| 102 | 57.05 | 78.17 | 50.37 | 42.62 | 91.17 | 80.63 | 80.73 | 60.17 | 73.60 | 37.21 | 57.78 | 32.89 | 35.15 | 63.44 | 24.89 | 46.99 | TRUE | TRUE |\n",
       "|  30 | 79.96 | 89.24 | 75.67 | 74.96 | 95.15 | 89.88 | 93.06 | 78.88 | 89.43 | 69.12 | 80.28 | 63.87 | 94.80 | 78.05 | 75.50 | 51.50 | TRUE | TRUE |\n",
       "| 126 | 54.08 | 54.01 | 57.65 | 50.59 | 66.19 | 55.23 | 44.42 | 50.21 | 60.96 | 55.47 | 52.18 | 61.98 | 60.94 | 53.10 | 57.41 | 30.90 | TRUE | TRUE |\n",
       "|  25 | 83.02 | 87.77 | 81.22 | 80.07 | 96.34 | 90.46 | 89.62 | 74.65 | 91.26 | 81.27 | 79.68 | 72.67 | 96.13 | 72.63 | 79.74 | 71.78 | TRUE | TRUE |\n",
       "|  78 | 66.45 | 83.38 | 61.98 | 54.01 | 94.83 | 83.59 | 90.46 | 64.64 | 70.86 | 62.24 | 69.04 | 45.77 | 50.86 | 61.19 | 40.63 | 63.34 | TRUE | TRUE |\n",
       "| 129 | 47.46 | 42.28 | 43.51 | 56.60 | 48.33 | 41.90 | 38.75 | 40.14 | 74.40 | 30.83 | 27.43 | 41.37 | 81.08 | 57.67 | 59.96 | 27.70 | TRUE | TRUE |\n",
       "| 123 | 54.34 | 67.05 | 53.59 | 42.39 | 74.20 | 64.51 | 66.93 | 62.58 | 53.26 | 48.73 | 51.75 | 60.60 | 45.60 | 58.42 | 33.21 | 32.32 | TRUE | TRUE |\n",
       "| ⋮ | ⋮ | ⋮ | ⋮ | ⋮ | ⋮ | ⋮ | ⋮ | ⋮ | ⋮ | ⋮ | ⋮ | ⋮ | ⋮ | ⋮ | ⋮ | ⋮ | ⋮ | ⋮ |\n",
       "|  56 | 71.89 | 79.38 | 69.84 | 66.44 | 88.35 | 81.83 | 88.12 | 59.23 | 90.63 | 76.71 | 49.96 | 62.05 | 77.12 | 69.74 | 50.87 | 68.04 | FALSE | TRUE |\n",
       "|  81 | 63.19 | 83.38 | 57.98 | 48.21 | 91.25 | 94.06 | 89.42 | 58.78 | 82.44 | 55.47 | 55.28 | 38.73 | 45.40 | 68.77 | 33.82 | 44.87 | FALSE | TRUE |\n",
       "|  12 | 86.65 | 89.32 | 87.27 | 83.38 | 92.87 | 96.17 | 90.05 | 78.18 | 93.23 | 95.24 | 82.54 | 78.07 | 93.30 | 85.26 | 76.88 | 78.06 | FALSE | TRUE |\n",
       "|  16 | 86.89 | 89.12 | 87.75 | 83.79 | 92.94 | 94.28 | 89.14 | 80.10 | 92.20 | 97.69 | 82.02 | 79.10 | 94.60 | 86.84 | 75.20 | 78.52 | FALSE | TRUE |\n",
       "|  19 | 85.42 | 87.59 | 82.68 | 86.00 | 93.02 | 93.87 | 92.71 | 70.75 | 93.05 | 89.04 | 74.66 | 73.98 | 95.94 | 84.53 | 75.16 | 88.36 | FALSE | TRUE |\n",
       "|  19 | 85.21 | 87.42 | 82.39 | 85.83 | 93.07 | 93.44 | 92.01 | 71.15 | 92.69 | 88.48 | 74.07 | 74.32 | 95.31 | 84.53 | 75.30 | 88.17 | FALSE | TRUE |\n",
       "|  20 | 84.99 | 87.28 | 83.27 | 84.42 | 93.10 | 93.35 | 91.80 | 70.87 | 93.39 | 91.01 | 74.13 | 74.55 | 92.26 | 84.93 | 72.34 | 88.15 | FALSE | TRUE |\n",
       "|  23 | 85.14 | 87.22 | 83.95 | 84.26 | 93.13 | 93.26 | 91.73 | 70.75 | 93.27 | 93.80 | 73.80 | 74.91 | 91.23 | 84.48 | 73.12 | 88.20 | FALSE | TRUE |\n",
       "|  24 | 85.04 | 87.42 | 84.15 | 83.54 | 93.18 | 94.01 | 91.31 | 71.19 | 92.74 | 95.14 | 73.39 | 75.32 | 88.88 | 84.14 | 73.02 | 88.12 | FALSE | TRUE |\n",
       "|  38 | 77.64 | 84.48 | 70.93 | 77.52 | 89.20 | 95.08 | 89.23 | 64.42 | 86.70 | 64.21 | 70.45 | 62.34 | 95.06 | 77.64 | 82.72 | 54.67 | FALSE | TRUE |\n",
       "|  39 | 77.67 | 84.17 | 70.81 | 78.02 | 89.30 | 93.78 | 88.51 | 65.10 | 86.79 | 63.67 | 70.30 | 62.46 | 95.06 | 78.07 | 82.48 | 56.46 | FALSE | TRUE |\n",
       "| 108 | 59.89 | 85.47 | 57.32 | 36.88 | 89.70 | 93.73 | 93.00 | 65.44 | 93.62 | 53.49 | 49.12 | 33.06 | 24.50 | 60.02 | 26.53 | 36.46 | FALSE | TRUE |\n",
       "| 103 | 61.50 | 85.80 | 57.62 | 41.07 | 89.97 | 92.78 | 92.46 | 67.97 | 92.51 | 56.51 | 48.62 | 32.84 | 37.84 | 60.41 | 28.18 | 37.86 | FALSE | TRUE |\n",
       "|  99 | 63.99 | 86.05 | 59.60 | 46.30 | 90.45 | 91.68 | 91.80 | 70.28 | 93.26 | 61.84 | 48.48 | 34.84 | 50.81 | 62.48 | 30.22 | 41.68 | FALSE | TRUE |\n",
       "|  90 | 63.82 | 74.66 | 65.38 | 51.44 | 87.37 | 79.54 | 83.53 | 48.18 | 76.73 | 68.96 | 54.89 | 60.92 | 52.87 | 60.59 | 51.34 | 40.97 | FALSE | TRUE |\n",
       "|  86 | 63.43 | 78.04 | 60.71 | 51.53 | 84.45 | 82.19 | 82.11 | 63.41 | 85.43 | 45.85 | 59.20 | 52.38 | 46.54 | 63.97 | 56.46 | 39.15 | FALSE | TRUE |\n",
       "|  84 | 65.18 | 79.22 | 64.56 | 51.77 | 85.29 | 84.22 | 83.74 | 63.62 | 86.23 | 57.37 | 60.06 | 54.60 | 46.54 | 63.88 | 55.49 | 41.18 | FALSE | TRUE |\n",
       "|  92 | 62.07 | 76.50 | 56.97 | 52.73 | 90.33 | 69.58 | 85.70 | 60.38 | 77.71 | 48.77 | 56.34 | 45.07 | 61.82 | 54.19 | 43.08 | 51.83 | FALSE | TRUE |\n",
       "|  92 | 63.03 | 77.07 | 60.16 | 51.85 | 90.76 | 71.19 | 86.46 | 59.87 | 81.69 | 52.45 | 59.64 | 46.86 | 60.80 | 53.13 | 41.54 | 51.92 | FALSE | TRUE |\n",
       "|  91 | 64.36 | 77.05 | 63.10 | 52.94 | 91.22 | 71.28 | 86.77 | 58.91 | 83.32 | 61.18 | 61.40 | 46.48 | 62.61 | 54.86 | 40.86 | 53.41 | FALSE | TRUE |\n",
       "| 159 | 40.22 | 55.90 | 37.23 | 27.52 | 62.73 | 45.25 | 66.76 | 48.85 | 40.88 | 39.43 | 34.02 | 34.59 | 34.16 | 38.11 | 11.45 | 26.36 | FALSE | TRUE |\n",
       "| 133 | 49.64 | 49.12 | 49.87 | 49.94 | 58.72 | 48.90 | 43.08 | 45.76 | 61.58 | 36.23 | 41.93 | 59.72 | 69.52 | 55.33 | 43.42 | 31.51 | FALSE | TRUE |\n",
       "| 130 | 50.43 | 49.86 | 51.40 | 50.03 | 59.57 | 50.81 | 45.09 | 43.98 | 60.40 | 42.79 | 42.43 | 59.98 | 66.93 | 56.34 | 45.00 | 31.84 | FALSE | TRUE |\n",
       "| 131 | 51.01 | 50.43 | 51.98 | 50.63 | 60.52 | 51.30 | 46.69 | 43.22 | 61.18 | 43.48 | 43.24 | 60.00 | 68.18 | 55.51 | 46.76 | 32.06 | FALSE | TRUE |\n",
       "| 133 | 51.21 | 50.99 | 53.48 | 49.15 | 61.26 | 49.79 | 47.95 | 44.96 | 62.32 | 48.19 | 43.33 | 60.09 | 62.78 | 55.31 | 46.25 | 32.28 | FALSE | TRUE |\n",
       "| 131 | 51.66 | 51.30 | 54.70 | 48.98 | 61.75 | 49.82 | 48.17 | 45.45 | 63.20 | 52.22 | 42.75 | 60.63 | 63.54 | 56.47 | 42.92 | 32.99 | FALSE | TRUE |\n",
       "| 137 | 44.29 | 48.11 | 46.11 | 38.64 | 44.53 | 57.40 | 48.55 | 41.94 | 77.41 | 19.28 | 28.85 | 58.91 | 53.36 | 56.03 | 19.02 | 26.12 | FALSE | TRUE |\n",
       "| 125 | 49.07 | 52.16 | 54.10 | 40.94 | 54.24 | 59.72 | 49.91 | 44.76 | 80.29 | 42.44 | 34.55 | 59.10 | 58.06 | 56.97 | 21.23 | 27.51 | FALSE | TRUE |\n",
       "| 130 | 51.18 | 55.28 | 56.35 | 41.90 | 61.09 | 62.57 | 51.55 | 45.91 | 76.98 | 51.34 | 37.95 | 59.12 | 57.10 | 56.52 | 24.09 | 29.90 | FALSE | TRUE |\n",
       "| 131 | 52.22 | 54.59 | 58.15 | 43.94 | 62.96 | 61.00 | 51.06 | 43.32 | 78.88 | 56.08 | 37.43 | 60.20 | 56.93 | 57.14 | 29.77 | 31.92 | FALSE | TRUE |\n",
       "\n"
      ],
      "text/plain": [
       "     rank_score_spi score_spi score_bhn score_fow score_opp score_nbmc score_ws\n",
       "1     80            67.59     79.16     65.40     58.22     86.67      86.44   \n",
       "2     97            60.10     74.55     51.25     54.49     72.88      83.35   \n",
       "3     46            73.96     81.88     70.69     69.32     86.33      88.07   \n",
       "4     84            62.86     79.45     61.22     47.92     83.91      77.71   \n",
       "5     99            61.43     77.84     57.63     48.83     87.72      78.15   \n",
       "6    150            45.57     47.15     45.21     44.34     54.66      47.82   \n",
       "7     74            66.56     80.41     62.82     56.46     92.38      78.47   \n",
       "8    105            59.45     66.16     54.62     57.56     72.21      66.32   \n",
       "9     36            79.93     88.01     77.07     74.71     91.17      94.88   \n",
       "10   143            44.25     54.20     46.20     32.34     66.70      55.90   \n",
       "11   154            46.58     44.86     48.63     46.24     55.91      30.89   \n",
       "12    69            67.71     80.42     69.13     53.59     91.56      82.05   \n",
       "13   168            32.39     28.96     33.29     34.91     36.38      21.97   \n",
       "14   141            48.89     63.31     48.66     34.69     74.23      63.23   \n",
       "15   164            37.97     56.86     35.38     21.67     60.12      54.29   \n",
       "16     1            90.53     91.18     90.79     89.61     93.87      98.79   \n",
       "17    64            70.85     79.02     71.16     62.36     85.50      83.44   \n",
       "18    75            66.15     68.20     62.45     67.78     73.34      71.66   \n",
       "19   125            47.13     44.10     46.95     50.33     57.05      41.28   \n",
       "20    86            65.13     75.15     61.19     59.06     77.30      83.87   \n",
       "21    27            82.26     92.60     83.01     71.16     95.39      98.89   \n",
       "22    81            63.98     76.05     61.00     54.90     84.32      79.66   \n",
       "23   144            48.89     52.80     54.34     39.54     74.38      56.89   \n",
       "24   102            57.05     78.17     50.37     42.62     91.17      80.63   \n",
       "25    30            79.96     89.24     75.67     74.96     95.15      89.88   \n",
       "26   126            54.08     54.01     57.65     50.59     66.19      55.23   \n",
       "27    25            83.02     87.77     81.22     80.07     96.34      90.46   \n",
       "28    78            66.45     83.38     61.98     54.01     94.83      83.59   \n",
       "29   129            47.46     42.28     43.51     56.60     48.33      41.90   \n",
       "30   123            54.34     67.05     53.59     42.39     74.20      64.51   \n",
       "⋮    ⋮              ⋮         ⋮         ⋮         ⋮         ⋮          ⋮       \n",
       "1999  56            71.89     79.38     69.84     66.44     88.35      81.83   \n",
       "2000  81            63.19     83.38     57.98     48.21     91.25      94.06   \n",
       "2001  12            86.65     89.32     87.27     83.38     92.87      96.17   \n",
       "2002  16            86.89     89.12     87.75     83.79     92.94      94.28   \n",
       "2003  19            85.42     87.59     82.68     86.00     93.02      93.87   \n",
       "2004  19            85.21     87.42     82.39     85.83     93.07      93.44   \n",
       "2005  20            84.99     87.28     83.27     84.42     93.10      93.35   \n",
       "2006  23            85.14     87.22     83.95     84.26     93.13      93.26   \n",
       "2007  24            85.04     87.42     84.15     83.54     93.18      94.01   \n",
       "2008  38            77.64     84.48     70.93     77.52     89.20      95.08   \n",
       "2009  39            77.67     84.17     70.81     78.02     89.30      93.78   \n",
       "2010 108            59.89     85.47     57.32     36.88     89.70      93.73   \n",
       "2011 103            61.50     85.80     57.62     41.07     89.97      92.78   \n",
       "2012  99            63.99     86.05     59.60     46.30     90.45      91.68   \n",
       "2013  90            63.82     74.66     65.38     51.44     87.37      79.54   \n",
       "2014  86            63.43     78.04     60.71     51.53     84.45      82.19   \n",
       "2015  84            65.18     79.22     64.56     51.77     85.29      84.22   \n",
       "2016  92            62.07     76.50     56.97     52.73     90.33      69.58   \n",
       "2017  92            63.03     77.07     60.16     51.85     90.76      71.19   \n",
       "2018  91            64.36     77.05     63.10     52.94     91.22      71.28   \n",
       "2019 159            40.22     55.90     37.23     27.52     62.73      45.25   \n",
       "2020 133            49.64     49.12     49.87     49.94     58.72      48.90   \n",
       "2021 130            50.43     49.86     51.40     50.03     59.57      50.81   \n",
       "2022 131            51.01     50.43     51.98     50.63     60.52      51.30   \n",
       "2023 133            51.21     50.99     53.48     49.15     61.26      49.79   \n",
       "2024 131            51.66     51.30     54.70     48.98     61.75      49.82   \n",
       "2025 137            44.29     48.11     46.11     38.64     44.53      57.40   \n",
       "2026 125            49.07     52.16     54.10     40.94     54.24      59.72   \n",
       "2027 130            51.18     55.28     56.35     41.90     61.09      62.57   \n",
       "2028 131            52.22     54.59     58.15     43.94     62.96      61.00   \n",
       "     score_sh score_ps score_abk score_aic score_hw score_eq score_pr score_pfc\n",
       "1    87.69    55.85    74.20     74.19     53.55    59.66    81.60    60.29    \n",
       "2    77.17    64.81    47.04     37.15     64.58    56.22    71.05    64.77    \n",
       "3    89.59    63.55    89.07     68.14     61.41    64.13    90.28    67.65    \n",
       "4    85.11    71.08    65.15     51.25     62.00    66.47    61.56    56.51    \n",
       "5    86.61    58.87    55.79     78.17     45.35    51.22    60.41    58.62    \n",
       "6    36.59    49.53    50.36     33.84     36.99    59.66    69.20    40.61    \n",
       "7    85.21    65.57    81.61     61.95     61.64    46.07    70.02    62.49    \n",
       "8    75.91    50.21    68.71     56.61     41.87    51.28    74.13    59.83    \n",
       "9    91.84    74.16    91.56     80.30     67.85    68.58    93.79    78.63    \n",
       "10   46.54    47.67    58.51     30.33     39.95    56.00    19.40    50.77    \n",
       "11   40.36    52.27    66.72     36.98     33.67    57.17    69.13    50.94    \n",
       "12   86.87    61.20    94.69     74.48     49.48    57.87    53.29    70.34    \n",
       "13   21.13    36.37    38.48     27.79     18.21    48.68    56.58    29.20    \n",
       "14   60.94    54.82    60.98     29.20     45.09    59.38    22.02    55.11    \n",
       "15   70.65    42.38    42.40     30.58     34.27    34.28    20.36    36.70    \n",
       "16   91.31    80.76    98.69     96.25     88.44    79.78    95.63    88.77    \n",
       "17   83.89    63.25    74.73     82.22     63.24    64.46    85.49    63.10    \n",
       "18   80.32    47.49    79.84     65.67     49.76    54.55    89.48    71.72    \n",
       "19   29.44    48.61    55.42     27.79     44.15    60.44    73.29    52.01    \n",
       "20   80.99    58.45    69.87     65.24     49.51    60.15    77.00    60.99    \n",
       "21   93.62    82.51    89.83     83.35     87.47    71.39    64.30    88.45    \n",
       "22   83.72    56.48    68.71     62.92     61.11    51.25    76.94    62.43    \n",
       "23   44.24    35.66    68.75     47.66     44.92    56.01    46.80    50.00    \n",
       "24   80.73    60.17    73.60     37.21     57.78    32.89    35.15    63.44    \n",
       "25   93.06    78.88    89.43     69.12     80.28    63.87    94.80    78.05    \n",
       "26   44.42    50.21    60.96     55.47     52.18    61.98    60.94    53.10    \n",
       "27   89.62    74.65    91.26     81.27     79.68    72.67    96.13    72.63    \n",
       "28   90.46    64.64    70.86     62.24     69.04    45.77    50.86    61.19    \n",
       "29   38.75    40.14    74.40     30.83     27.43    41.37    81.08    57.67    \n",
       "30   66.93    62.58    53.26     48.73     51.75    60.60    45.60    58.42    \n",
       "⋮    ⋮        ⋮        ⋮         ⋮         ⋮        ⋮        ⋮        ⋮        \n",
       "1999 88.12    59.23    90.63     76.71     49.96    62.05    77.12    69.74    \n",
       "2000 89.42    58.78    82.44     55.47     55.28    38.73    45.40    68.77    \n",
       "2001 90.05    78.18    93.23     95.24     82.54    78.07    93.30    85.26    \n",
       "2002 89.14    80.10    92.20     97.69     82.02    79.10    94.60    86.84    \n",
       "2003 92.71    70.75    93.05     89.04     74.66    73.98    95.94    84.53    \n",
       "2004 92.01    71.15    92.69     88.48     74.07    74.32    95.31    84.53    \n",
       "2005 91.80    70.87    93.39     91.01     74.13    74.55    92.26    84.93    \n",
       "2006 91.73    70.75    93.27     93.80     73.80    74.91    91.23    84.48    \n",
       "2007 91.31    71.19    92.74     95.14     73.39    75.32    88.88    84.14    \n",
       "2008 89.23    64.42    86.70     64.21     70.45    62.34    95.06    77.64    \n",
       "2009 88.51    65.10    86.79     63.67     70.30    62.46    95.06    78.07    \n",
       "2010 93.00    65.44    93.62     53.49     49.12    33.06    24.50    60.02    \n",
       "2011 92.46    67.97    92.51     56.51     48.62    32.84    37.84    60.41    \n",
       "2012 91.80    70.28    93.26     61.84     48.48    34.84    50.81    62.48    \n",
       "2013 83.53    48.18    76.73     68.96     54.89    60.92    52.87    60.59    \n",
       "2014 82.11    63.41    85.43     45.85     59.20    52.38    46.54    63.97    \n",
       "2015 83.74    63.62    86.23     57.37     60.06    54.60    46.54    63.88    \n",
       "2016 85.70    60.38    77.71     48.77     56.34    45.07    61.82    54.19    \n",
       "2017 86.46    59.87    81.69     52.45     59.64    46.86    60.80    53.13    \n",
       "2018 86.77    58.91    83.32     61.18     61.40    46.48    62.61    54.86    \n",
       "2019 66.76    48.85    40.88     39.43     34.02    34.59    34.16    38.11    \n",
       "2020 43.08    45.76    61.58     36.23     41.93    59.72    69.52    55.33    \n",
       "2021 45.09    43.98    60.40     42.79     42.43    59.98    66.93    56.34    \n",
       "2022 46.69    43.22    61.18     43.48     43.24    60.00    68.18    55.51    \n",
       "2023 47.95    44.96    62.32     48.19     43.33    60.09    62.78    55.31    \n",
       "2024 48.17    45.45    63.20     52.22     42.75    60.63    63.54    56.47    \n",
       "2025 48.55    41.94    77.41     19.28     28.85    58.91    53.36    56.03    \n",
       "2026 49.91    44.76    80.29     42.44     34.55    59.10    58.06    56.97    \n",
       "2027 51.55    45.91    76.98     51.34     37.95    59.12    57.10    56.52    \n",
       "2028 51.06    43.32    78.88     56.08     37.43    60.20    56.93    57.14    \n",
       "     score_incl score_aae is_train x   \n",
       "1    40.24      50.73     TRUE     TRUE\n",
       "2    56.12      26.03     TRUE     TRUE\n",
       "3    68.48      50.87     TRUE     TRUE\n",
       "4    48.70      24.90     TRUE     TRUE\n",
       "5    35.57      40.72     TRUE     TRUE\n",
       "6    41.81      25.72     TRUE     TRUE\n",
       "7    36.89      56.45     TRUE     TRUE\n",
       "8    55.73      40.54     TRUE     TRUE\n",
       "9    58.23      68.19     TRUE     TRUE\n",
       "10   36.76      22.42     TRUE     TRUE\n",
       "11   35.03      29.85     TRUE     TRUE\n",
       "12   38.38      52.35     TRUE     TRUE\n",
       "13   30.39      23.47     TRUE     TRUE\n",
       "14   38.55      23.10     TRUE     TRUE\n",
       "15    5.20      24.44     TRUE     TRUE\n",
       "16   90.78      83.26     TRUE     TRUE\n",
       "17   41.77      59.06     TRUE     TRUE\n",
       "18   57.10      52.82     TRUE     TRUE\n",
       "19   46.61      29.40     TRUE     TRUE\n",
       "20   53.60      44.64     TRUE     TRUE\n",
       "21   65.15      66.72     TRUE     TRUE\n",
       "22   41.95      38.29     TRUE     TRUE\n",
       "23   28.36      32.99     TRUE     TRUE\n",
       "24   24.89      46.99     TRUE     TRUE\n",
       "25   75.50      51.50     TRUE     TRUE\n",
       "26   57.41      30.90     TRUE     TRUE\n",
       "27   79.74      71.78     TRUE     TRUE\n",
       "28   40.63      63.34     TRUE     TRUE\n",
       "29   59.96      27.70     TRUE     TRUE\n",
       "30   33.21      32.32     TRUE     TRUE\n",
       "⋮    ⋮          ⋮         ⋮        ⋮   \n",
       "1999 50.87      68.04     FALSE    TRUE\n",
       "2000 33.82      44.87     FALSE    TRUE\n",
       "2001 76.88      78.06     FALSE    TRUE\n",
       "2002 75.20      78.52     FALSE    TRUE\n",
       "2003 75.16      88.36     FALSE    TRUE\n",
       "2004 75.30      88.17     FALSE    TRUE\n",
       "2005 72.34      88.15     FALSE    TRUE\n",
       "2006 73.12      88.20     FALSE    TRUE\n",
       "2007 73.02      88.12     FALSE    TRUE\n",
       "2008 82.72      54.67     FALSE    TRUE\n",
       "2009 82.48      56.46     FALSE    TRUE\n",
       "2010 26.53      36.46     FALSE    TRUE\n",
       "2011 28.18      37.86     FALSE    TRUE\n",
       "2012 30.22      41.68     FALSE    TRUE\n",
       "2013 51.34      40.97     FALSE    TRUE\n",
       "2014 56.46      39.15     FALSE    TRUE\n",
       "2015 55.49      41.18     FALSE    TRUE\n",
       "2016 43.08      51.83     FALSE    TRUE\n",
       "2017 41.54      51.92     FALSE    TRUE\n",
       "2018 40.86      53.41     FALSE    TRUE\n",
       "2019 11.45      26.36     FALSE    TRUE\n",
       "2020 43.42      31.51     FALSE    TRUE\n",
       "2021 45.00      31.84     FALSE    TRUE\n",
       "2022 46.76      32.06     FALSE    TRUE\n",
       "2023 46.25      32.28     FALSE    TRUE\n",
       "2024 42.92      32.99     FALSE    TRUE\n",
       "2025 19.02      26.12     FALSE    TRUE\n",
       "2026 21.23      27.51     FALSE    TRUE\n",
       "2027 24.09      29.90     FALSE    TRUE\n",
       "2028 29.77      31.92     FALSE    TRUE"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data |>\n",
    "    mutate(x = TRUE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Delete Column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-30T14:33:43.649449Z",
     "start_time": "2020-06-30T14:33:43.611681Z"
    },
    "scrolled": true,
    "slideshow": {
     "slide_type": "subslide"
    },
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# data |> select(-x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Replace Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-30T14:33:43.649449Z",
     "start_time": "2020-06-30T14:33:43.611681Z"
    },
    "scrolled": true,
    "slideshow": {
     "slide_type": "subslide"
    },
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# data |> mutate(x = case_when(...))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Rank Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='darkgrey'><b>Operation</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-18T14:08:51.549157Z",
     "start_time": "2020-09-18T14:08:51.517907Z"
    },
    "scrolled": true,
    "slideshow": {
     "slide_type": "subslide"
    },
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# data |> mutate(rank = order(n_vacunas))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Categorical Variable Transformation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Encode Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# data |> mutate(x = if_else(x = 'Yes', 1, 0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Ordinal Encoding Transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# data |> mutate(x = fct_reorder(...))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### One Hot Encoding Transform"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Dummy Variable Encoding Transform"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Embedding Transformation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Specific encode for text mining context. No code here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Numeric Variable Transformation: Scale"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Data to Transform"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Evaluating Normalization Tranform"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Evaluating Standarization Transform"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Normalization Transform"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='tomato'>Select columns</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# vars <- c()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='darkgrey'><b>Operation</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Standarization Transform"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='tomato'>Select columns</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "vars <- sapply(data, is.numeric)\n",
    "vars[\"rank_score_spi\"] <- FALSE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='darkgrey'><b>Operation</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-02T17:51:47.944300Z",
     "start_time": "2021-01-02T17:51:47.859685Z"
    },
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "data[vars] <- lapply(data[vars], scale)\n",
    "\n",
    "data[vars] <- lapply(data[vars], function(column) {\n",
    "    as.numeric(scale(column))\n",
    "})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Numeric Variable Transformation: Distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "###\tDiscretization Transform"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "##### Evaluating Discretization Transformations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Uniform Discretization Transform"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='tomato'>Select columns</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-31T17:31:51.827830Z",
     "start_time": "2020-12-31T17:31:51.812208Z"
    },
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# retrieve just the numeric input values\n",
    "# vars <- c(...)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='darkgrey'><b>Operation</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-31T10:45:07.969795Z",
     "start_time": "2020-12-31T10:45:07.938574Z"
    },
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# data |> mutate(across(vars), cut(breaks = 10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Power Transform"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Data to Transform"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "##### Evaluating Box-Cox tranform"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "##### Evaluating Yeo-Johnson tranform"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Box-Cox Transform"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='tomato'>Select columns</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='darkgrey'><b>Operation</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-04T18:58:42.800879Z",
     "start_time": "2021-01-04T18:58:31.271283Z"
    },
    "scrolled": true,
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Yeo-Johnson Transform"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='tomato'>Select columns</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='darkgrey'><b>Operation</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='green'>Data Save</font>\n",
    "\n",
    "* Solo si se han hecho cambios\n",
    "\n",
    "* No aplica"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='tomato'> Identificamos los datos a guardar</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "data_to_save <- data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<font color='tomato'>Estructura de nombre de archivos:</font>\n",
    "\n",
    "* Código del caso de uso, por ejemplo \"CU_04\"\n",
    "* Número del proceso que lo genera, por ejemplo \"_06\".\n",
    "* Resto del nombre del archivo de entrada\n",
    "* Extensión del archivo\n",
    "\n",
    "Ejemplo: \"CU_04_06_01_01_zonasgeo.json, primer fichero que se genera en la tarea 01 del proceso 05 (Data Collection) para el caso de uso 04 (vacunas) y que se ha transformado en el proceso 06\n",
    "\n",
    "Importante mantener los guiones bajos antes de proceso, tarea, archivo y nombre"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Proceso 14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "caso <- \"CU_53\"\n",
    "proceso <- '_14'\n",
    "tarea <- \"_02\"\n",
    "archivo <- \"\"\n",
    "proper <- \"_spi\"\n",
    "extension <- \".csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='tomato'><b> OPCION A:</b> Uso del paquete \"tcltk\" para mayor comodidad</font>\n",
    "\n",
    "* Buscar carpeta, escribir nombre de archivo SIN extensión (se especifica en el código)\n",
    "* Especificar sufijo2 si es necesario\n",
    "* Cambiar datos por datos_xx si es necesario"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# file_save <- paste0(caso, proceso, tarea, tcltk::tkgetSaveFile(), proper, extension) \n",
    "# path_out <- paste0(oPath, file_save)\n",
    "# write_csv(data_to_save_xxxxx, path_out)\n",
    "\n",
    "# cat('File saved as: ')\n",
    "# path_out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='tomato'><b> OPCION B:</b> Especificar el nombre de archivo</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Los ficheros de salida del proceso van siempre a Data/Output/.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File saved as: "
     ]
    },
    {
     "data": {
      "text/html": [
       "'Data/Output/CU_53_14_02_spi.csv'"
      ],
      "text/latex": [
       "'Data/Output/CU\\_53\\_14\\_02\\_spi.csv'"
      ],
      "text/markdown": [
       "'Data/Output/CU_53_14_02_spi.csv'"
      ],
      "text/plain": [
       "[1] \"Data/Output/CU_53_14_02_spi.csv\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "file_save <- paste0(caso, proceso, tarea, archivo, proper, extension) \n",
    "path_out <- paste0(oPath, file_save)\n",
    "write_csv(data_to_save, path_out)\n",
    "\n",
    "cat('File saved as: ')\n",
    "path_out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Copia del fichero a Input\n",
    "\n",
    "Si el archivo se va a usar en otros notebooks, copiar a la carpeta Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "TRUE"
      ],
      "text/latex": [
       "TRUE"
      ],
      "text/markdown": [
       "TRUE"
      ],
      "text/plain": [
       "[1] TRUE"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "path_in <- paste0(iPath, file_save)\n",
    "file.copy(path_out, path_in, overwrite = TRUE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='#2874a6'>REPORT</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuación se realizará un informe de las acciones realizadas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=' #2874a6 '>Main Actions Carried Out</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Si eran necesarias se han realizado en el proceso 05 por cuestiones de eficiencia\n",
    "- O bien se hacen en el dominio IV o V para integrar en el pipeline de modelización"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=' #2874a6 '>Main Conclusions</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Los datos están listos para la modelización y despliegue\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='RED'>CODE TO DEPLOY (PILOT)</font>\n",
    "\n",
    "A continuación se incluirá el código que deba ser llevado a despliegue para producción, dado que se entiende efectúa operaciones necesarias sobre los datos en la ejecución del prototipo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=' red '><b>Description</b></font>\n",
    "\n",
    "- No hay nada que desplegar en el piloto, ya que estos datos son estáticos o en todo caso cambian con muy poca frecuencia, altamente improbable durante el proyecto.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=' red '><b>CODE</b></font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "celltoolbar": "Slideshow",
  "hide_input": false,
  "kernelspec": {
   "display_name": "R [conda env:citizenlab] *",
   "language": "R",
   "name": "conda-env-citizenlab-r"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.2.0"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": true,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "450.433px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
