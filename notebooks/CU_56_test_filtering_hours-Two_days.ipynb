{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9ee07070",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import copy\n",
    "import multiprocessing\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from deap import base\n",
    "from deap import creator\n",
    "from deap import tools\n",
    "from datetime import datetime, timedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5b2be327",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load files\n",
    "file_name='RECINTO.csv'\n",
    "RECINTO = pd.read_csv('./Data/'+file_name)\n",
    "file_name='EVENTO.csv'\n",
    "ORIGINAL_EVENTO = pd.read_csv('./Data/'+file_name)\n",
    "file_name='PERFILES.csv'\n",
    "PERFILES = pd.read_csv('./Data/'+file_name)\n",
    "file_name='PREFERENCIAS_US1.csv'\n",
    "PREFERENCIAS = pd.read_csv('./Data/'+file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "87bc4adc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform to date and hour formats\n",
    "ORIGINAL_EVENTO['Hora_apertura_1'] = pd.to_datetime(ORIGINAL_EVENTO['Hora_apertura_1'], format='%H:%M')\n",
    "ORIGINAL_EVENTO['Hora_cierre_1'] = pd.to_datetime(ORIGINAL_EVENTO['Hora_cierre_1'], format='%H:%M')\n",
    "ORIGINAL_EVENTO['Fecha_1'] = pd.to_datetime(ORIGINAL_EVENTO['Fecha_1'], format='%m/%d/%Y')\n",
    "\n",
    "ORIGINAL_EVENTO['Hora_apertura_2'] = pd.to_datetime(ORIGINAL_EVENTO['Hora_apertura_2'], format='%H:%M')\n",
    "ORIGINAL_EVENTO['Hora_cierre_2'] = pd.to_datetime(ORIGINAL_EVENTO['Hora_cierre_2'], format='%H:%M')\n",
    "ORIGINAL_EVENTO['Fecha_2'] = pd.to_datetime(ORIGINAL_EVENTO['Fecha_2'], format='%m/%d/%Y')\n",
    "drop_list = []\n",
    "\n",
    "# Exclude resources of more than 6 hours of duration\n",
    "for i in range(0, max(ORIGINAL_EVENTO['Id_Recurso'])):\n",
    "    \n",
    "    # Get open time for the first resource\n",
    "    ha1 = ORIGINAL_EVENTO.Hora_apertura_1[i]\n",
    "                        \n",
    "    # Get close time for the first resource\n",
    "    hc1 = ORIGINAL_EVENTO.Hora_cierre_1[i]\n",
    "    \n",
    "     # Get open time for the first resource\n",
    "    ha2 = ORIGINAL_EVENTO.Hora_apertura_2[i]\n",
    "                        \n",
    "    # Get close time for the first resource\n",
    "    hc2 = ORIGINAL_EVENTO.Hora_cierre_2[i]\n",
    "                        \n",
    "    diff_hour1 = (hc1 - ha1)\n",
    "    diff_hour1 = diff_hour1 / np.timedelta64(1, 'm')\n",
    "    \n",
    "    diff_hour2 = (hc2 - ha2)\n",
    "    diff_hour2 = diff_hour2 / np.timedelta64(1, 'm')\n",
    "    \n",
    "    if diff_hour1 >= 360 or diff_hour2 >= 360:\n",
    "        drop_list.append(i)\n",
    "        \n",
    "# Get the two datasets (first with short durations and second with large duration)\n",
    "EVENTO = ORIGINAL_EVENTO[~ORIGINAL_EVENTO['Id_Recurso'].isin(drop_list)]\n",
    "EVENTO_HOURLESS = ORIGINAL_EVENTO[ORIGINAL_EVENTO['Id_Recurso'].isin(drop_list)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d0092d3d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Size of the individual\n",
    "SIZE_INDIVIDUAL = EVENTO.shape[0]\n",
    "\n",
    "# Number of generations\n",
    "NUM_GENERATIONS = 20\n",
    "\n",
    "# Optimal value to obtain (not reached)\n",
    "MAX_VALUE = SIZE_INDIVIDUAL + 10 * SIZE_INDIVIDUAL\n",
    "\n",
    "# Poblation members\n",
    "SIZE_POBLATION = 1000\n",
    "\n",
    "# CXPB  is the probability with which two individuals are crossed\n",
    "CXPB = 0.5\n",
    "\n",
    "# MUTPB is the probability for mutating an individual\n",
    "MUTPB = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bb174042",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the fitness function for maximizing the result\n",
    "creator.create(\"FitnessMax\", base.Fitness, weights=(1.0,))\n",
    "\n",
    "# Creation of the individual with the fitness function\n",
    "creator.create(\"Individual\", list, fitness=creator.FitnessMax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1a8b14a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a toolbox for the genetic algorithm\n",
    "toolbox = base.Toolbox()\n",
    "\n",
    "# Attribute generator having only 0, 1 or 2 in the body of the individual (no day, first day or second day)\n",
    "toolbox.register(\"attr_int\", random.randint, 0, 2)\n",
    "\n",
    "# Structure initializers\n",
    "toolbox.register(\"individual\", tools.initRepeat, creator.Individual, toolbox.attr_int, SIZE_INDIVIDUAL)\n",
    "toolbox.register(\"population\", tools.initRepeat, list, toolbox.individual)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "78d800bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enable multiprocessing\n",
    "pool = multiprocessing.Pool()\n",
    "toolbox.register(\"map\", pool.map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d07f012d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to find overlapped hours between resources\n",
    "def find_hour_overlapping(ha1, hc1, ha2, hc2):\n",
    "    found = False\n",
    "    if (ha1 == ha2) or (ha2 < ha1 < hc2) or (ha1 < ha2 < hc1) or (ha2 < ha1 < hc1 < hc2) \\\n",
    "        or (ha1 < ha2 < hc2 < hc1):\n",
    "        found = True\n",
    "    return found"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4832b5cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to find overlapped hours in the first day\n",
    "def find_first_day_overlapping(i, j):\n",
    "    found = False\n",
    "    # Get date for the first resource\n",
    "    date_1 = EVENTO.Fecha_1[EVENTO.index[i]]\n",
    "\n",
    "    # Get date for the second resource\n",
    "    date_2 = EVENTO.Fecha_1[EVENTO.index[j]]\n",
    "\n",
    "    # Evaluate if the resource is in the same day\n",
    "    if (date_1 - date_2).days == 0:\n",
    "        # Get open time for the first resource\n",
    "        ha1 = EVENTO.Hora_apertura_1[EVENTO.index[i]]\n",
    "\n",
    "        # Get close time for the first resource\n",
    "        hc1 = EVENTO.Hora_cierre_1[EVENTO.index[i]]\n",
    "\n",
    "        # Get open time for the second resource\n",
    "        ha2 = EVENTO.Hora_apertura_1[EVENTO.index[j]]\n",
    "\n",
    "        # Get close time for the second resource\n",
    "        hc2 = EVENTO.Hora_cierre_1[EVENTO.index[j]]\n",
    "                            \n",
    "        found = find_hour_overlapping(ha1, hc1, ha2, hc2)\n",
    "    return found"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4088bca8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to find overlapped hours in the second day\n",
    "def find_second_day_overlapping(i, j):\n",
    "    found = False\n",
    "    # Get date for the first resource\n",
    "    date_1 = EVENTO.Fecha_2[EVENTO.index[i]]\n",
    "\n",
    "    # Get date for the second resource\n",
    "    date_2 = EVENTO.Fecha_2[EVENTO.index[j]]\n",
    "\n",
    "    # Evaluate if the resource is in the same day\n",
    "    if (date_1 - date_2).days == 0:\n",
    "        # Get open time for the first resource\n",
    "        ha1 = EVENTO.Hora_apertura_2[EVENTO.index[i]]\n",
    "\n",
    "        # Get close time for the first resource\n",
    "        hc1 = EVENTO.Hora_cierre_2[EVENTO.index[i]]\n",
    "\n",
    "        # Get open time for the second resource\n",
    "        ha2 = EVENTO.Hora_apertura_2[EVENTO.index[j]]\n",
    "\n",
    "        # Get close time for the second resource\n",
    "        hc2 = EVENTO.Hora_cierre_2[EVENTO.index[j]]\n",
    "        \n",
    "        # Exclude resources that are not active in the second day\n",
    "        if ha2.hour == 0 and hc2.hour == 0:\n",
    "            found = True\n",
    "        else:\n",
    "            found = find_hour_overlapping(ha1, hc1, ha2, hc2)\n",
    "    return found"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5b4d506e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Overlapping function to detect time problems in resources\n",
    "def find_overlapping(individual):\n",
    "    found = False\n",
    "    i = 0\n",
    "    while i < len(individual) and not found:\n",
    "        # If the resource is selected for the algorithm for day 1\n",
    "        if individual[i] == 1:\n",
    "            j = 0\n",
    "            while j < len(individual)  and not found:\n",
    "                if i != j:\n",
    "                    if individual[j] == 1:\n",
    "                        found = find_first_day_overlapping(i, j)\n",
    "                j = j + 1\n",
    "        # If the resource is selected for the algorithm for day 2\n",
    "        elif individual[i] == 2:\n",
    "            j = 0\n",
    "            while j < len(individual)  and not found:\n",
    "                if i != j:\n",
    "                    if individual[j] == 2:\n",
    "                        found = find_second_day_overlapping(i, j)\n",
    "                j = j + 1\n",
    "        i = i + 1\n",
    "\n",
    "    return found"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c46a1fe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fitness function\n",
    "def evalOneMax(individual):\n",
    "    summa = 0\n",
    "    if not find_overlapping(individual):\n",
    "        for i in range(0, len(individual)):\n",
    "            if individual[i] == 2:\n",
    "                ha = EVENTO.Hora_apertura_2[EVENTO.index[i]]\n",
    "                hc = EVENTO.Hora_cierre_2[EVENTO.index[i]]\n",
    "                # Only if the resource is active in the second day it is considered\n",
    "                if ha.hour != 0 and hc != 0:\n",
    "                    summa = 1 + summa + PREFERENCIAS[PREFERENCIAS['Id_Recurso'] == EVENTO.index[i]].Preferencia.values[0]\n",
    "            elif individual[i] == 1:\n",
    "                summa = 1 + summa + PREFERENCIAS[PREFERENCIAS['Id_Recurso'] == EVENTO.index[i]].Preferencia.values[0]\n",
    "    return summa,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "32d50fcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Record the allowed operations\n",
    "toolbox.register(\"evaluate\", evalOneMax)\n",
    "toolbox.register(\"mate\", tools.cxTwoPoint)\n",
    "toolbox.register(\"mutate\", tools.mutUniformInt, low=0, up=2, indpb=0.05)\n",
    "toolbox.register(\"select\", tools.selTournament, tournsize=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "61b593b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initial population\n",
    "pop = toolbox.population(n=SIZE_POBLATION)\n",
    "for i in range(0, SIZE_POBLATION):\n",
    "    pop[i] =  creator.Individual(SIZE_INDIVIDUAL * [0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3d72f565",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the entire population\n",
    "fitnesses = list(map(toolbox.evaluate, pop))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ec12e387",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store the values of the fitness function for each individual\n",
    "for ind, fit in zip(pop, fitnesses):\n",
    "    ind.fitness.values = fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5b448665",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for calculating the stats each generation\n",
    "def calculate_statistics(fits, g=0):\n",
    "    print(\"-- Generation %i --\" % g)   \n",
    "    length = len(pop)\n",
    "    mean = sum(fits) / length\n",
    "    sum2 = sum(x*x for x in fits)\n",
    "    std = abs(sum2 / length - mean**2)**0.5\n",
    "    print(\"  Min %s\" % min(fits))\n",
    "    print(\"  Max %s\" % max(fits))\n",
    "    print(\"  Avg %s\" % mean)\n",
    "    print(\"  Std %s\" % std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b83d80d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Generation 0 --\n",
      "  Min 0.0\n",
      "  Max 0.0\n",
      "  Avg 0.0\n",
      "  Std 0.0\n"
     ]
    }
   ],
   "source": [
    "# Gather all the fitnesses in one list and print the stats\n",
    "fits = [ind.fitness.values[0] for ind in pop]\n",
    "calculate_statistics(fits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "323e36a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Generation 1 --\n",
      "  Min 0.0\n",
      "  Max 36.0\n",
      "  Avg 1.128\n",
      "  Std 3.9728599270550684\n",
      "-- Generation 2 --\n",
      "  Min 0.0\n",
      "  Max 36.0\n",
      "  Avg 3.356\n",
      "  Std 6.192032299657359\n",
      "-- Generation 3 --\n",
      "  Min 0.0\n",
      "  Max 60.0\n",
      "  Avg 7.479\n",
      "  Std 8.437153489181052\n",
      "-- Generation 4 --\n",
      "  Min 0.0\n",
      "  Max 60.0\n",
      "  Avg 12.401\n",
      "  Std 10.077906479026286\n",
      "-- Generation 5 --\n",
      "  Min 0.0\n",
      "  Max 60.0\n",
      "  Avg 16.401\n",
      "  Std 12.269889934306665\n",
      "-- Generation 6 --\n",
      "  Min 0.0\n",
      "  Max 64.0\n",
      "  Avg 20.277\n",
      "  Std 14.267525048164451\n",
      "-- Generation 7 --\n",
      "  Min 0.0\n",
      "  Max 64.0\n",
      "  Avg 24.029\n",
      "  Std 15.837555335341374\n",
      "-- Generation 8 --\n",
      "  Min 0.0\n",
      "  Max 72.0\n",
      "  Avg 26.708\n",
      "  Std 18.545423586426924\n",
      "-- Generation 9 --\n",
      "  Min 0.0\n",
      "  Max 73.0\n",
      "  Avg 32.757\n",
      "  Std 19.56752286315261\n",
      "-- Generation 10 --\n",
      "  Min 0.0\n",
      "  Max 73.0\n",
      "  Avg 36.639\n",
      "  Std 22.352285766784565\n",
      "-- Generation 11 --\n",
      "  Min 0.0\n",
      "  Max 82.0\n",
      "  Avg 40.611\n",
      "  Std 24.243425479911046\n",
      "-- Generation 12 --\n",
      "  Min 0.0\n",
      "  Max 84.0\n",
      "  Avg 43.782\n",
      "  Std 26.66177931046614\n",
      "-- Generation 13 --\n",
      "  Min 0.0\n",
      "  Max 87.0\n",
      "  Avg 47.397\n",
      "  Std 28.025905712394025\n",
      "-- Generation 14 --\n",
      "  Min 0.0\n",
      "  Max 96.0\n",
      "  Avg 50.074\n",
      "  Std 30.184375494616418\n",
      "-- Generation 15 --\n",
      "  Min 0.0\n",
      "  Max 99.0\n",
      "  Avg 53.731\n",
      "  Std 31.92207134570061\n",
      "-- Generation 16 --\n",
      "  Min 0.0\n",
      "  Max 100.0\n",
      "  Avg 57.83\n",
      "  Std 33.37012286462247\n",
      "-- Generation 17 --\n",
      "  Min 0.0\n",
      "  Max 101.0\n",
      "  Avg 58.775\n",
      "  Std 36.49003117291078\n",
      "-- Generation 18 --\n",
      "  Min 0.0\n",
      "  Max 109.0\n",
      "  Avg 62.734\n",
      "  Std 37.47101872113967\n",
      "-- Generation 19 --\n",
      "  Min 0.0\n",
      "  Max 109.0\n",
      "  Avg 64.073\n",
      "  Std 39.99289525653277\n",
      "-- Generation 20 --\n",
      "  Min 0.0\n",
      "  Max 109.0\n",
      "  Avg 69.628\n",
      "  Std 40.00332006221483\n"
     ]
    }
   ],
   "source": [
    "# Variable keeping track of the number of generations\n",
    "g = 0\n",
    "\n",
    "# Begin the evolution\n",
    "while max(fits) < MAX_VALUE and g < NUM_GENERATIONS:\n",
    "    # A new generation\n",
    "    g = g + 1\n",
    "    \n",
    "    # Select the next generation individuals\n",
    "    offspring = toolbox.select(pop, len(pop))\n",
    "    \n",
    "    # Clone the selected individuals\n",
    "    offspring = list(map(toolbox.clone, offspring))\n",
    "    \n",
    "    # Apply crossover and mutation on the offspring\n",
    "    for child1, child2 in zip(offspring[::2], offspring[1::2]):\n",
    "        if random.random() < CXPB:\n",
    "            toolbox.mate(child1, child2)\n",
    "            del child1.fitness.values\n",
    "            del child2.fitness.values\n",
    "\n",
    "    for mutant in offspring:\n",
    "        if random.random() < MUTPB:\n",
    "            toolbox.mutate(mutant)\n",
    "            del mutant.fitness.values\n",
    "            \n",
    "    # Evaluate the individuals with an invalid fitness\n",
    "    invalid_ind = [ind for ind in offspring if not ind.fitness.valid]\n",
    "    fitnesses = map(toolbox.evaluate, invalid_ind)\n",
    "    for ind, fit in zip(invalid_ind, fitnesses):\n",
    "        ind.fitness.values = fit\n",
    "        \n",
    "    pop[:] = offspring\n",
    "    # Gather all the fitnesses in one list and print the stats\n",
    "    fits = [ind.fitness.values[0] for ind in pop]\n",
    "    calculate_statistics(fits, g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "86d32910",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 0, 1, 1, 0, 0, 2, 2, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "# Find and print best individual\n",
    "best_index = fits.index(max(fits))\n",
    "best_partial_individual = pop[best_index]\n",
    "print(best_partial_individual)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "72531518",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 2023-10-02 00:00:00 1900-01-01 11:00:00 1900-01-01 12:00:00\n",
      "3 2023-10-02 00:00:00 1900-01-01 16:00:00 1900-01-01 17:00:00\n",
      "26 2023-10-02 00:00:00 1900-01-01 19:00:00 1900-01-01 20:00:00\n",
      "31 2023-10-02 00:00:00 1900-01-01 17:00:00 1900-01-01 18:00:00\n",
      "35 2023-10-02 00:00:00 1900-01-01 10:00:00 1900-01-01 10:30:00\n",
      "46 2023-10-02 00:00:00 1900-01-01 18:00:00 1900-01-01 18:30:00\n",
      "54 2023-10-02 00:00:00 1900-01-01 20:00:00 1900-01-01 21:00:00\n",
      "55 2023-10-02 00:00:00 1900-01-01 21:00:00 1900-01-01 22:00:00\n",
      "88 2023-10-02 00:00:00 1900-01-01 12:00:00 1900-01-01 16:00:00\n",
      "7 2023-11-02 00:00:00 1900-01-01 11:00:00 1900-01-01 12:00:00\n",
      "8 2023-11-02 00:00:00 1900-01-01 16:00:00 1900-01-01 16:30:00\n",
      "11 2023-11-02 00:00:00 1900-01-01 19:00:00 1900-01-01 20:00:00\n",
      "96 2023-11-02 00:00:00 1900-01-01 20:00:00 1900-01-01 23:00:00\n"
     ]
    }
   ],
   "source": [
    "# Print the selected resources by the genetic algorithm for the two days\n",
    "for i in range(0,len(best_partial_individual)):\n",
    "    if best_partial_individual[i] == 1:\n",
    "        print(EVENTO.Id_Recurso[EVENTO.index[i]], EVENTO.Fecha_1[EVENTO.index[i]], EVENTO.Hora_apertura_1[EVENTO.index[i]], EVENTO.Hora_cierre_1[EVENTO.index[i]])\n",
    "\n",
    "for i in range(0,len(best_partial_individual)):\n",
    "    if best_partial_individual[i] == 2:\n",
    "        print(EVENTO.Id_Recurso[EVENTO.index[i]], EVENTO.Fecha_2[EVENTO.index[i]], EVENTO.Hora_apertura_2[EVENTO.index[i]], EVENTO.Hora_cierre_2[EVENTO.index[i]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a04ba20b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the large duration resources\n",
    "best_individual = copy.copy(best_partial_individual)\n",
    "for value in list(EVENTO_HOURLESS.Id_Recurso):\n",
    "    best_individual.insert(value,'#')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "84816c12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 2023-10-02 00:00:00 1900-01-01 11:00:00 1900-01-01 12:00:00 Firma de discos de Sabina\n",
      "3 2023-10-02 00:00:00 1900-01-01 16:00:00 1900-01-01 17:00:00 Expositor Sabina\n",
      "5 2023-10-02 00:00:00 1900-01-01 16:00:00 1900-01-01 22:00:00 Merchandisig Sabina\n",
      "18 2023-10-02 00:00:00 1900-01-01 08:00:00 1900-01-01 20:00:00 Puesto de venta de merchandising pop español\n",
      "19 2023-10-02 00:00:00 1900-01-01 08:00:00 1900-01-01 20:00:00 Expositor historia del pop español\n",
      "26 2023-10-02 00:00:00 1900-01-01 19:00:00 1900-01-01 20:00:00 Concierto Tina & Joe\n",
      "27 2023-10-02 00:00:00 1900-01-01 08:00:00 1900-01-01 20:00:00 Expositor jazz es futuro\n",
      "31 2023-10-02 00:00:00 1900-01-01 17:00:00 1900-01-01 18:00:00 Concierto Maluma\n",
      "34 2023-10-02 00:00:00 1900-01-01 08:00:00 1900-01-01 20:00:00 Mechandising Reggaeton\n",
      "35 2023-10-02 00:00:00 1900-01-01 10:00:00 1900-01-01 10:30:00 Firma Kase.O\n",
      "41 2023-10-02 00:00:00 1900-01-01 08:00:00 1900-01-01 20:00:00 Rap y sus barrios\n",
      "46 2023-10-02 00:00:00 1900-01-01 18:00:00 1900-01-01 18:30:00 Firma Sevendust\n",
      "48 2023-10-02 00:00:00 1900-01-01 08:00:00 1900-01-01 20:00:00 Musica alternativa 80s\n",
      "54 2023-10-02 00:00:00 1900-01-01 20:00:00 1900-01-01 21:00:00 Concierto sinfonico Real Conservatorio Superior de Música de Madrid\n",
      "55 2023-10-02 00:00:00 1900-01-01 21:00:00 1900-01-01 22:00:00 Concierto coro Escuela Superior de Música Reina Sofía\n",
      "56 2023-10-02 00:00:00 1900-01-01 10:00:00 1900-01-01 20:00:00 Conservatorios Madrid\n",
      "57 2023-10-02 00:00:00 1900-01-01 08:00:00 1900-01-01 20:00:00 Chopper Monster\n",
      "58 2023-10-02 00:00:00 1900-01-01 08:00:00 1900-01-01 20:00:00 AllfonRock\n",
      "59 2023-10-02 00:00:00 1900-01-01 08:00:00 1900-01-01 20:00:00 Musical Henares\n",
      "60 2023-10-02 00:00:00 1900-01-01 08:00:00 1900-01-01 20:00:00 La cara B\n",
      "61 2023-10-02 00:00:00 1900-01-01 08:00:00 1900-01-01 20:00:00 Jazzymas\n",
      "62 2023-10-02 00:00:00 1900-01-01 08:00:00 1900-01-01 20:00:00 Musical Princesa\n",
      "63 2023-10-02 00:00:00 1900-01-01 08:00:00 1900-01-01 20:00:00 Nakasha\n",
      "64 2023-10-02 00:00:00 1900-01-01 08:00:00 1900-01-01 20:00:00 La Gramola\n",
      "65 2023-10-02 00:00:00 1900-01-01 08:00:00 1900-01-01 20:00:00 Discos La Metralleta\n",
      "66 2023-10-02 00:00:00 1900-01-01 08:00:00 1900-01-01 20:00:00 Marilians Records\n",
      "67 2023-10-02 00:00:00 1900-01-01 08:00:00 1900-01-01 20:00:00 Denied Rock\n",
      "68 2023-10-02 00:00:00 1900-01-01 08:00:00 1900-01-01 20:00:00 New Rock Fuencarral\n",
      "69 2023-10-02 00:00:00 1900-01-01 08:00:00 1900-01-01 20:00:00 Popping\n",
      "70 2023-10-02 00:00:00 1900-01-01 08:00:00 1900-01-01 20:00:00 Atlántica Pop\n",
      "71 2023-10-02 00:00:00 1900-01-01 08:00:00 1900-01-01 20:00:00 Spiccato\n",
      "72 2023-10-02 00:00:00 1900-01-01 08:00:00 1900-01-01 20:00:00 Directa Music\n",
      "73 2023-10-02 00:00:00 1900-01-01 08:00:00 1900-01-01 20:00:00 Stomp Zion\n",
      "74 2023-10-02 00:00:00 1900-01-01 08:00:00 1900-01-01 20:00:00 Red Bubble\n",
      "75 2023-10-02 00:00:00 1900-01-01 08:00:00 1900-01-01 20:00:00 G music\n",
      "76 2023-10-02 00:00:00 1900-01-01 08:00:00 1900-01-01 20:00:00 UrbanoShop\n",
      "77 2023-10-02 00:00:00 1900-01-01 10:00:00 1900-01-01 22:00:00 Perritos calientes\n",
      "78 2023-10-02 00:00:00 1900-01-01 10:00:00 1900-01-01 22:00:00 Hamburguesa\n",
      "79 2023-10-02 00:00:00 1900-01-01 10:00:00 1900-01-01 22:00:00 Frutos Secos\n",
      "80 2023-10-02 00:00:00 1900-01-01 10:00:00 1900-01-01 22:00:00 Pizza Kebab\n",
      "81 2023-10-02 00:00:00 1900-01-01 10:00:00 1900-01-01 22:00:00 Cerveceria\n",
      "82 2023-10-02 00:00:00 1900-01-01 10:00:00 1900-01-01 22:00:00 Barbacoa\n",
      "83 2023-10-02 00:00:00 1900-01-01 10:00:00 1900-01-01 22:00:00 Food Truck\n",
      "84 2023-10-02 00:00:00 1900-01-01 10:00:00 1900-01-01 22:00:00 Starbucks Coffe\n",
      "85 2023-10-02 00:00:00 1900-01-01 10:00:00 1900-01-01 22:00:00 Hard Rock\n",
      "86 2023-10-02 00:00:00 1900-01-01 10:00:00 1900-01-01 22:00:00 grido\n",
      "87 2023-10-02 00:00:00 1900-01-01 10:00:00 1900-01-01 22:00:00 llaollao\n",
      "88 2023-10-02 00:00:00 1900-01-01 12:00:00 1900-01-01 16:00:00 Dominos pizza\n",
      "7 2023-11-02 00:00:00 1900-01-01 11:00:00 1900-01-01 12:00:00 Concierto Coldplay\n",
      "8 2023-11-02 00:00:00 1900-01-01 16:00:00 1900-01-01 16:30:00 Firma de discos de Bombay\n",
      "11 2023-11-02 00:00:00 1900-01-01 19:00:00 1900-01-01 20:00:00 Concierto de Los Zigarros\n",
      "96 2023-11-02 00:00:00 1900-01-01 20:00:00 1900-01-01 23:00:00 Templo de bambú\n"
     ]
    }
   ],
   "source": [
    "# Print the selected resources including short and long duration ones\n",
    "for i in range(0,len(best_individual)):\n",
    "    if best_individual[i] == '#' or best_individual[i] == 1:\n",
    "        print(ORIGINAL_EVENTO.Id_Recurso[ORIGINAL_EVENTO.index[i]], ORIGINAL_EVENTO.Fecha_1[ORIGINAL_EVENTO.index[i]], ORIGINAL_EVENTO.Hora_apertura_1[ORIGINAL_EVENTO.index[i]], ORIGINAL_EVENTO.Hora_cierre_1[ORIGINAL_EVENTO.index[i]], ORIGINAL_EVENTO.Nombre[ORIGINAL_EVENTO.index[i]])\n",
    "    \n",
    "for i in range(0,len(best_individual)):\n",
    "    if best_individual[i] == 2:\n",
    "        print(ORIGINAL_EVENTO.Id_Recurso[ORIGINAL_EVENTO.index[i]], ORIGINAL_EVENTO.Fecha_2[ORIGINAL_EVENTO.index[i]], ORIGINAL_EVENTO.Hora_apertura_2[ORIGINAL_EVENTO.index[i]], ORIGINAL_EVENTO.Hora_cierre_2[ORIGINAL_EVENTO.index[i]], ORIGINAL_EVENTO.Nombre[ORIGINAL_EVENTO.index[i]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9a355ec",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
